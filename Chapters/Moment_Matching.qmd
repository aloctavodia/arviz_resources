# Moment Matching for Improved PSIS-LOO-CV {#sec-moment-matching}

```{python}
#| echo: false
#| warning: false
import numpy as np
import matplotlib.pyplot as plt
import lzma
from pathlib import Path

import arviz.preview as azp
azp.style.use("arviz-variat")

plt.rcParams["figure.dpi"] = 100
SEED = 4711
```

## Overview

Evaluating model generalization is central to Bayesian analysis. PSIS-LOO-CV provides an efficient way to approximate leave-one-out cross-validation without refitting the model $n$ times. However, this efficiency depends critically on stable importance sampling, which breaks down when the Pareto-$k$ diagnostic exceeds a sample-size dependent threshold (typically around 0.7 for standard MCMC sample sizes), leading to unreliable estimates. 

When observations produce high Pareto-$k$ values, we can use standard LOO-CV for those observations, i.e. refit the model while removing those problematic observations one at a time. This could be useful if the number of observations with high $\hat k$ is small, otherwise it can easily become too expensive for routine use. K-fold CV is another option but it can also be too expensive.

But those are not the only two solution when PSIS-LOO-CV gives high $\hat k$ values. Instead of expensive model refitting. The method **importance weighted moment matching (IWMM)** presented by @paananen_2020 works by improving the proposal distribution by iteratively transforming existing posterior draws to better match the moments of the target distribution.

In this chapter, we'll explore the theory behind IWMM and walk through a complete example. We'll fit a Poisson regression model to the `roaches` data from @gelman_hill_2007, which examines the efficacy of a pest management system at reducing cockroach infestations in urban apartments. The model is intentionally misspecified to demonstrate the benefits of moment matching when influential observations lead to high Pareto-$k$ values.

## Background

### Importance sampling for PSIS-LOO-CV

Recall from @sec-model-comparison that PSIS-LOO-CV uses importance sampling to approximate leave-one-out cross-validation without refitting the model. Instead of refitting for each observation $i$, we reweight draws from the full-data posterior $p(\theta \mid y)$ using importance weights

$$
w_i(\theta) = \frac{1}{p(y_i \mid \theta)}
$$

to approximate the leave-one-out posterior $p(\theta \mid y_{-i})$. When observation $i$ is influential, these weights become highly variable. The Pareto-$k$ diagnostic quantifies this instability by fitting a generalized Pareto distribution to the tail of the importance weight distribution. When $k > 0.7$, the importance weights remain too unstable even after Pareto smoothing, indicating unreliable approximations. Moment matching offers a solution by transforming the posterior draws to improve the proposal distribution. For detailed coverage of PSIS-LOO-CV, see @sec-model-comparison.

### Monte Carlo estimators

To understand how moment matching improves these importance weights, we first need to understand which Monte Carlo estimator we are using. Two of the most commonly used estimators are standard importance sampling (IS) and self-normalized importance sampling (SNIS). The choice between IS and SNIS determines which proposal distribution works best, which in turn affects how moment matching should adapt the draws.

The central problem we're interested in is computing $\mathbb{E}_p[h(\theta)] = \int h(\theta) p(\theta) \, d\theta$ using draws $\{\theta^{(s)}\}_{s=1}^S$ from a proposal distribution $g(\theta)$.

#### Standard Importance Sampling (IS)

The standard importance sampling estimator computes the expectation as
$$
\hat{\mu}_{\text{IS}} = \frac{1}{S} \sum_{s=1}^S w^{(s)} h(\theta^{(s)}), \quad w^{(s)} = \frac{p(\theta^{(s)})}{g(\theta^{(s)})},
$$

which is unbiased when normalizing constants are known, with variance depending on how well $g(\theta)$ matches the target in regions where $|h(\theta)|$ is large.

#### Self-Normalized Importance Sampling (SNIS)

The SNIS estimator computes the ratio of weighted averages as
$$
\hat{\mu}_{\text{SNIS}} = \frac{\sum_{s=1}^S w^{(s)} h(\theta^{(s)})}{\sum_{s=1}^S w^{(s)}}, \quad w^{(s)} = \frac{p(\theta^{(s)})}{g(\theta^{(s)})}.
$$

This is a natural choice for PSIS-LOO-CV because the normalizing constants of $p(\theta \mid y_{-i})$ and $p(\theta \mid y)$ are typically unknown.

SNIS introduces an additional consideration. We need to estimate both numerator and denominator accurately, which changes which regions of the proposal matter most. The optimal proposal for SNIS emphasizes where $|h(\theta) - \mathbb{E}_p[h(\theta)]|$ is large, whereas for standard IS it emphasizes where $|h(\theta)|$ is large. In practice, we use self-normalized weights $\tilde{w}^{(s)} = w^{(s)} / \sum_{r=1}^S w^{(r)}$ for moment matching since normalizing constants are often unknown.

## Multiple importance sampling

The distinction between numerator and denominator adaptation for SNIS creates a challenge. As we will see later, the optimal proposal for the numerator differs from the optimal proposal for the denominator. Rather than choosing between these competing proposals, moment matching uses multiple importance sampling to combine them. MIS provides a principled framework for sampling from $J$ different proposal distributions and combining the results into a single estimator with provably good properties.

Suppose we independently draw $S_j$ samples from each of $J$ proposal distributions $g_1(\theta), \ldots, g_J(\theta)$, with $\sum_{j=1}^J S_j = S$ total draws. The multiple importance sampling estimator is

$$\hat{\mu}_{\mathrm{MIS}} = \sum_{j=1}^{J} \frac{1}{S_j} \sum_{s=1}^{S_j} \beta_j(\theta^{(j,s)}) \frac{p(\theta^{(j,s)})}{g_j(\theta^{(j,s)})} h(\theta^{(j,s)}),$$

where $\{\beta_j(\theta)\}_{j=1}^{J}$ forms a partition of unity with $\beta_j(\theta) \geq 0$ and $\sum_{j=1}^J \beta_j(\theta) = 1$ for all $\theta$. The weighting functions $\beta_j$ determine how much each proposal contributes at different points in the parameter space.

A natural choice for the weighting functions is the *balance heuristic*

$$\beta_j(\theta) = \frac{S_j g_j(\theta)}{\sum_{k=1}^J S_k g_k(\theta)}.$$

A critical property of this weighting function is that it can be shown that the variance of the MIS estimator using the balance heuristic is provably smaller than the variance of any single proposal distribution, plus a term that vanishes as the sample sizes grow.

Intuitively, the balance heuristic computes importance weights as if all draws came from a mixture proposal $g_{\alpha}(\theta) = \sum_{j=1}^J \alpha_j g_j(\theta)$ where $\alpha_j = S_j / S$, which gives us the weights

$$w^{(j,s)} = \frac{p(\theta^{(j,s)})}{g_{\alpha}(\theta^{(j,s)})} = \frac{p(\theta^{(j,s)})}{\sum_{j=1}^J \alpha_j g_j(\theta^{(j,s)})}.$$

This framework becomes crucial for moment matching when adapting two separate proposal distributions, because rather than choosing between them, we can combine both using MIS and the balance heuristic.

## Importance weighted moment matching

Moment matching extends the idea of PSIS-LOO-CV in a clever way. It *implicitly* updates the proposal without needing auxiliary parameters or resampling. Traditional adaptive importance sampling alternates between drawing samples, computing weights, and updating parameters. The key insight from @paananen_2020 is simpler: skip generating fresh draws and instead repeatedly transform the existing draws from $p(\theta \mid y)$ in the unconstrained parameter space. These transformations align the low-order moments of the draws with the moments implied by the leave-one-out weights.

This implicit adaptation is fully automated and requires only operations on already available posterior draws. It's designed to plug into PSIS-LOO-CV pipelines that flag problematic cases using the Pareto-$k$ diagnostic from @vehtari_2017. Because we reuse the same Monte Carlo sample throughout, the computational cost stays close to that of a single PSIS-LOO-CV evaluation, even when several adaptation rounds are attempted. Importantly, this approach preserves the effective sample size accrued during the original posterior simulation and avoids delicate tuning choices.

The approach involves several key components:

- Apply affine transformations to existing draws to better match the target distribution
- Recognize that different Monte Carlo estimators require different proposal strategies
- Identify optimal proposal distributions for both standard and self-normalized importance sampling
- Approximate the challenging self-normalized optimal proposal using a split proposal that separates numerator and denominator adaptation
- Combine the adapted proposals using multiple importance sampling

The following sections develop each of these ideas in turn.

### Affine transformations and implicit adaptation

The core idea of importance weighted moment matching (IWMM) is to transform existing draws to better match the target distribution without resampling. We achieve this using affine transformations guided by importance-weighted moments.

Consider a set of draws $\{\theta^{(s)}\}_{s=1}^S$ from the full-data posterior $p(\theta \mid y)$. A generic affine transformation consists of a square matrix $\mathbf{A}$ and a translation vector $\mathbf{b}$ such that

$$
T(\theta^{(s)}) = \mathbf{A}\theta^{(s)} + \mathbf{b} = \theta^{*(s)}.
$$

Since the transformations are affine and the same for all draws, the implicit density of the transformed draws is

$$
g_T(\theta^{*(s)}) = p(\theta^{(s)} \mid y) |\mathbf{J}_T|^{-1},
$$

where $|\mathbf{J}_T|^{-1} = |\det(\mathbf{A})|^{-1}$ is the inverse Jacobian determinant. Crucially, this allows us to evaluate the proposal density at the transformed draws without ever writing down an explicit functional form. The proposal is adapted *implicitly* through the transformation, which requires an invertible matrix $\mathbf{A}$ so that the Jacobian determinant is well defined.

When moment matching is applied to leave-one-out cross-validation, the importance weights must be recomputed after each transformation. For a transformed draw $\theta^{*(s)}$, the importance weight becomes

$$
w_{\text{loo}, i}^{*(s)} = \frac{p(\theta^{*(s)} \mid y)}{p(\theta^{(s)} \mid y) \, p(y_i \mid \theta^{*(s)})} \propto \frac{p(\theta^{*(s)} \mid y_{-i})}{p(\theta^{(s)} \mid y)},
$$

which is still proportional to the ratio of the LOO posterior to the original proposal. This reweighting accounts for both the density of the transformed draw under the full-data posterior and its likelihood for observation $i$. The denominator term $p(\theta^{(s)} \mid y)$ remains constant for each draw across all LOO folds, but the numerator terms must be evaluated at each transformed location.

### Targeting optimal proposal distributions

The affine transformations need some target to guide them. The choice of target determines whether moment matching successfully reduces the Pareto-$k$ diagnostic. The theoretically optimal proposal density depends on both the function $h(\theta)$ being estimated and the weighting scheme used.

For standard importance sampling, the optimal proposal is

$$
g_{\mathrm{IS}}^{\mathrm{opt}}(\theta) \propto p(\theta)\lvert h(\theta)\rvert,
$$

which emphasizes regions where $|h(\theta)|$ is large. For self-normalized importance sampling, the optimal proposal is

$$
g_{\mathrm{SNIS}}^{\mathrm{opt}}(\theta) \propto p(\theta)\left|h(\theta)-\mathbb{E}_{p}[h(\theta)]\right|,
$$

which emphasizes regions where $h(\theta)$ deviates from its expectation.

The difference arises because SNIS must estimate both numerator and denominator accurately. When $h(\theta)$ varies substantially, we need draws where $h(\theta)$ deviates most from its mean. When $h(\theta)$ is roughly constant, we need draws emphasizing posterior mass. Moment matching uses the available importance weights to steer affine transformations toward these optimal shapes.

To make this work in practice, we use two types of weights:

- **Common weights** $w^{(s)} = p(\theta^{(s)}) / g(\theta^{(s)})$ quantify the mismatch between proposal and target independent of the function $h$
- **Expectation-specific weights** $v^{(s)} = h(\theta^{(s)}) w^{(s)}$ weight each draw by both the density ratio and the integrand value

The transformations are calibrated with $\{w^{(s)}\}$ or with $\{|v^{(s)}|\}$, depending on whether the denominator or numerator of the SNIS estimator needs improvement. We use absolute values $|v^{(s)}|$ because both positive and negative values of $h(\theta)$ contribute equally to variance, so we want draws where the magnitude is large regardless of sign.

### The split proposal for SNIS

The SNIS optimal proposal from the previous section presents a practical challenge. It can easily be multimodal even when the expectation is defined over a unimodal distribution, making it difficult to approximate with simple affine transformations. It also depends on the unknown expectation $\mathbb{E}_p[h(\theta)]$.

#### The split proposal approximation

To combine the two adaptation strategies into an efficient proposal distribution, @paananen_2020 develop a practical approximation called the *split proposal density* given by

$$
g_{\mathrm{SNIS}}^{\mathrm{split}}(\theta) \propto |h(\theta)|p(\theta) + \mathbb{E}_{p}[h(\theta)]p(\theta).
$$

This approximation splits the piecewise-defined optimal proposal into two clear components. The first component $|h(\theta)|p(\theta)$ is proportional to the optimal proposal for standard importance sampling and uses the absolute expectation-specific weights $\{|v^{(s)}|\}$. The second component $\mathbb{E}_{p}[h(\theta)]p(\theta)$ is proportional to the target distribution $p(\theta)$ itself and uses the common weights $\{w^{(s)}\}$. This split form is a convenient approximation that has similar tail behavior to the SNIS optimal proposal while being simpler to work with. It avoids the potentially complex multimodal structure of $|h(\theta) - \mathbb{E}_p[h(\theta)]|$ by separating it into two interpretable components.

The trade-off is that this approximation places unnecessary probability mass in regions where $h(\theta) \approx \mathbb{E}_p[h(\theta)]$, thus losing some efficiency. However, the approximation works best precisely when we need it most. When $p(\theta)$ is more distinct from $p(\theta)|h(\theta)|$, the value of $\mathbb{E}_p[h(\theta)]$ becomes smaller and the approximation becomes closer to the optimal form. These are exactly the cases when adaptive importance sampling is most beneficial.

#### Double adaptation strategy

The split proposal naturally suggests a double adaptation strategy. We run two separate moment matching procedures in parallel: one uses the absolute expectation-specific weights $\{|v^{(s)}|\}$ to approximate the first component, and the other uses the common weights $\{w^{(s)}\}$ to approximate the second. These two adapted proposal distributions are then combined using multiple importance sampling with the balance heuristic.

When $h(\theta) \geq 0$, both components integrate to $\mathbb{E}_p[h(\theta)]$. @paananen_2020 show that equal allocation (50-50 split) is provably optimal in this case and more generally is a conservative choice that guarantees the asymptotic variance is never more than twice that of using the better component alone. 

### Three moment matching transformations

Our overall goal is to transform the existing posterior draws to match the optimal proposals. To do this, we match progressively more moments of the distribution to importance-weighted moments.

@paananen_2020 recommend a sequence of three affine transformations with increasing complexity. The transformations use importance weights to identify where the target distribution places its mass relative to the proposal. We start with the simplest transformation and progress to more complex ones only when simpler ones no longer improve the Pareto-$k$ diagnostic.

**Transformation $T_1$ (matching the mean).** The simplest transformation shifts the sample mean to match the importance-weighted mean

$$
\theta^{*(s)} = T_1(\theta^{(s)}) = \theta^{(s)} - \bar{\theta} + \bar{\theta}_w,
$$

where the unweighted mean is $\bar{\theta} = \frac{1}{S} \sum_{s=1}^S \theta^{(s)}$ and the self-normalized importance-weighted mean is

$$
\bar{\theta}_w = \frac{\sum_{s=1}^S w^{(s)} \theta^{(s)}}{\sum_{s=1}^S w^{(s)}} = \sum_{s=1}^S \tilde{w}^{(s)} \theta^{(s)},
$$

with $\tilde{w}^{(s)} = w^{(s)} / \sum_{r=1}^S w^{(r)}$ denoting the self-normalized weights.

**Transformation $T_2$ (matching marginal variances).** The second transformation matches both the mean and the marginal variances

$$
\theta^{*(s)} = T_2(\theta^{(s)}) = \mathbf{v}_w^{1/2} \circ \mathbf{v}^{-1/2} \circ (\theta^{(s)} - \bar{\theta}) + \bar{\theta}_w,
$$

where $\circ$ denotes element-wise multiplication, $\mathbf{v}$ is the vector of unweighted marginal variances, and $\mathbf{v}_w$ is the vector of importance-weighted marginal variances computed as

$$
\mathbf{v}_w = \sum_{s=1}^S \tilde{w}^{(s)} (\theta^{(s)} - \bar{\theta}_w) \circ (\theta^{(s)} - \bar{\theta}_w) = \frac{\sum_{s=1}^S w^{(s)} (\theta^{(s)} - \bar{\theta}_w) \circ (\theta^{(s)} - \bar{\theta}_w)}{\sum_{s=1}^S w^{(s)}}.
$$

**Transformation $T_3$ (matching the covariance).** The most sophisticated transformation matches the full covariance structure

$$
\theta^{*(s)} = T_3(\theta^{(s)}) = \mathbf{L}_w \mathbf{L}^{-1} (\theta^{(s)} - \bar{\theta}) + \bar{\theta}_w,
$$

where $\mathbf{L}\mathbf{L}^\top = \boldsymbol{\Sigma}$ and $\mathbf{L}_w\mathbf{L}_w^\top = \boldsymbol{\Sigma}_w$ are Cholesky decompositions of the sample and weighted covariance matrices, with the weighted covariance computed as

$$
\boldsymbol{\Sigma}_w = \sum_{s=1}^S \tilde{w}^{(s)} (\theta^{(s)} - \bar{\theta}_w)(\theta^{(s)} - \bar{\theta}_w)^\top = \frac{\sum_{s=1}^S w^{(s)} (\theta^{(s)} - \bar{\theta}_w)(\theta^{(s)} - \bar{\theta}_w)^\top}{\sum_{s=1}^S w^{(s)}}.
$$

## The moment matching algorithm

The ArviZ implementation uses a greedy search strategy for each observation with high Pareto-$k$ values. For each problematic observation, the algorithm iteratively tries the three transformations in sequence. When the mean shift transformation ($T_1$) reduces the Pareto-$k$ diagnostic, it is accepted and the algorithm restarts from $T_1$ again. Only when $T_1$ fails to improve the diagnostic does the algorithm try the variance transformation ($T_2$), and similarly for the covariance transformation ($T_3$) when enabled. This process continues until no transformation improves the diagnostic or the maximum number of iterations is reached.

After the transformations converge, ArviZ applies an optional split proposal strategy by default. The cumulative transformation is applied to the first half of the posterior draws while the inverse transformation is applied to the second half. These two sets of transformed draws are then combined using multiple importance sampling with the balance heuristic. This split approach helps avoid potential bias from reusing the same draws and often improves the stability of the final estimates. The entire workflow is automated through the `loo_moment_match()` function.

## Roaches data and Poisson regression model

Let's now walk through a concrete example using the roaches dataset to see this algorithm in action. The roaches dataset from @gelman_hill_2007 examines the efficacy of a pest management system at reducing cockroach infestations in urban apartments. The study followed 264 apartments over several months, recording the number of roaches caught during follow-up (`y`), pre-treatment roach counts (`roach1`, square root transformed), treatment status (`treatment`), whether the building is restricted to elderly residents (`senior`), and trap exposure time in days (`exposure2`).

We intentionally use a Poisson model rather than negative binomial regression to demonstrate how moment matching handles misspecified models. The exposure time varies across apartments, so we include `log(exposure2)` as an offset term.

### Loading and preparing the data

We start by loading the roaches dataset and examining its basic structure.

```{python}
import pandas as pd

roaches = pd.read_csv("../data/roaches.csv", index_col=0)
roaches['log_exposure2'] = np.log(roaches['exposure2'])

roaches.describe()
```

The dataset exhibits substantial overdispersion with mean 25.6 and standard deviation 50.8. Approximately 36% of apartments had zero roaches while the maximum reached 357. This combination of high variability, many zeros, and extreme counts makes certain observations potentially influential, which is precisely where moment matching becomes valuable for improving LOO-CV estimates.

### Model specification and fitting

We fit a Poisson regression model using Bambi, which provides a high-level interface for Bayesian modeling. The model includes the pre-treatment roach count, treatment indicator, and senior building indicator as predictors, with log exposure as an offset.

::: {.panel-tabset}
## Bambi

```{python}
#| eval: false
import bambi as bmb

model = bmb.Model(
    'y ~ roach1 + treatment + senior + offset(log_exposure2)',
    data=roaches,
    family='poisson',
    priors={
        'roach1': bmb.Prior('Normal', mu=0, sigma=2.5),
        'treatment': bmb.Prior('Normal', mu=0, sigma=2.5),
        'senior': bmb.Prior('Normal', mu=0, sigma=2.5),
        'Intercept': bmb.Prior('Normal', mu=0, sigma=5.0)
    }
)

idata = model.fit(
    draws=1000,
    tune=1000,
    chains=4,
    random_seed=SEED,
    idata_kwargs={'log_likelihood': True}
)
```

## CmdStanPy

``` {.python}
# CmdStanPy implementation will be added in future
```
:::

```{python}
#| echo: false
import xarray as xr

idata = azp.convert_to_datatree("../models/prerun/moment_matching_00.nc")

# Rename __obs__ to obs_id to avoid dimension name conflict in moment matching
idata['log_likelihood'] = xr.DataTree(idata['log_likelihood'].ds.rename({'__obs__': 'obs_id'}))
idata['observed_data'] = xr.DataTree(idata['observed_data'].ds.rename({'__obs__': 'obs_id'}))
```

```{python}
azp.summary(idata.posterior.ds, var_names=['roach1', 'treatment', 'senior', 'Intercept'])
```

### Initial PSIS-LOO-CV evaluation

With the posterior draws in hand, we compute the PSIS-LOO-CV estimate of the model's predictive performance.

```{python}
loo_result = azp.loo(idata, pointwise=True, var_name="y")
loo_result
```

The output shows that 13 observations have Pareto-$k$ values exceeding 0.7, indicating that the importance sampling approximation is unreliable for these cases. For these problematic observations, the most accurate (but computationally expensive) approach would be to refit the model, leaving out each observation in turn. However, this quickly becomes impractical as the number of flagged observations grows. Moment matching offers an efficient solution by improving the reliability of the PSIS-LOO-CV estimates for exactly those cases where brute-force refitting would otherwise be required, reducing computational burden without sacrificing much accuracy.

## Applying moment matching

Now we apply importance weighted moment matching to improve the PSIS-LOO-CV estimates for the problematic observations. ArviZ implements this through the `loo_moment_match()` function, which requires us to provide the unconstrained parameter draws and functions for evaluating the model's log posterior and log likelihood.

### Function specification and implementation

To apply moment matching, we need to provide functions that compute the log posterior $\log p(\theta \mid y)$ and the log likelihood for a single observation $\log p(y_i \mid \theta)$ in the unconstrained parameter space, where all parameters are real-valued without constraints.

Our Poisson regression model is

$$
y_i \sim \text{Poisson}(\lambda_i), \quad \lambda_i = \exp(\eta_i),
$$

where the linear predictor is

$$
\eta_i = \alpha + \sum_{j=1}^3 \beta_j x_{ij} + \log(\text{exposure2}_i),
$$

with $x_i = (\text{roach1}_i, \text{treatment}_i, \text{senior}_i)$. We use independent normal priors $\beta_j \sim N(0, 2.5^2)$ and $\alpha \sim N(0, 5^2)$.

The log posterior combines the log likelihood with the log prior

$$
\log p(\theta \mid y) = \sum_{i=1}^n \log p(y_i \mid \theta) + \log p(\theta),
$$

where the log likelihood for observation $i$ is

$$
\log p(y_i \mid \theta) = y_i \log(\lambda_i) - \lambda_i - \log(y_i!).
$$

We start by converting our data into `DataArrays` with properly labeled dimensions to use xarray's dimension-aware operations for the computations.

```{python}
import xarray as xr
from scipy.special import gammaln
from functools import partial

X = roaches[['roach1', 'treatment', 'senior']].values
y = roaches['y'].values
log_offset = roaches['log_exposure2'].values

n_obs = len(roaches)
coef_names = ['roach1', 'treatment', 'senior']

design_matrix = xr.DataArray(
    X,
    dims=['obs_id', 'coef'],
    coords={'obs_id': range(n_obs), 'coef': coef_names}
)
y_da = xr.DataArray(y, dims=['obs_id'], coords={'obs_id': range(n_obs)})
offset_da = xr.DataArray(log_offset, dims=['obs_id'], coords={'obs_id': range(n_obs)})
factorial_term = xr.DataArray(gammaln(y + 1), dims=['obs_id'], coords={'obs_id': range(n_obs)})

beta_prior_scale = 2.5
alpha_prior_scale = 5.0
```

First, we construct an array of unconstrained parameters from the posterior draws. All of the parameters are unconstrained in this model, so we can simply concatenate the posterior draws along the `uparam` dimension.

```{python}
posterior = idata.posterior
upars = xr.concat([
    posterior.ds['roach1'].expand_dims({'uparam': ['roach1']}),
    posterior.ds['treatment'].expand_dims({'uparam': ['treatment']}),
    posterior.ds['senior'].expand_dims({'uparam': ['senior']}),
    posterior.ds['Intercept'].expand_dims({'uparam': ['Intercept']})
], dim='uparam').transpose('chain', 'draw', 'uparam')
```

We can now define the log posterior function and the leave-one-out log likelihood function. The log posterior function computes the log posterior probability for a given set of unconstrained parameters, and the log likelihood function computes the log likelihood for a given set of unconstrained parameters and a given observation.

```{python}
def log_prob_upars_fn(upars, design_matrix, y_da, offset_da, factorial_term,
                       coef_names, beta_prior_scale, alpha_prior_scale):
    """Compute log posterior for unconstrained parameters."""
    beta = upars.sel(uparam=coef_names).rename({'uparam': 'coef'})
    intercept = upars.sel(uparam='Intercept')

    lin = xr.dot(design_matrix, beta, dims='coef') + intercept + offset_da
    exp_lin = xr.ufuncs.exp(lin)
    log_lik = y_da * lin - exp_lin - factorial_term

    log_prior_beta = (-0.5 * (beta / beta_prior_scale) ** 2).sum('coef')
    log_prior_intercept = -0.5 * (intercept / alpha_prior_scale) ** 2
    return log_lik.sum('obs_id') + log_prior_beta + log_prior_intercept


def log_lik_i_upars_fn(upars, i, design_matrix, y_da, offset_da, factorial_term, coef_names):
    """Compute log likelihood for observation i."""
    beta = upars.sel(uparam=coef_names).rename({'uparam': 'coef'})
    intercept = upars.sel(uparam='Intercept')

    features_i = design_matrix.isel(obs_id=i)
    lin_i = (beta * features_i).sum('coef') + intercept + offset_da.isel(obs_id=i)

    exp_lin_i = xr.ufuncs.exp(lin_i)
    log_lik_i = y_da.isel(obs_id=i) * lin_i - exp_lin_i - factorial_term.isel(obs_id=i)
    return log_lik_i
```

Now we bind the data dependencies to these functions using `functools.partial`. This creates new functions where all the data parameters are fixed, leaving only the unconstrained parameters (and observation index for the likelihood function) as free parameters.

```{python}
log_prob_upars = partial(
    log_prob_upars_fn,
    design_matrix=design_matrix,
    y_da=y_da,
    offset_da=offset_da,
    factorial_term=factorial_term,
    coef_names=coef_names,
    beta_prior_scale=beta_prior_scale,
    alpha_prior_scale=alpha_prior_scale
)

log_lik_i_upars = partial(
    log_lik_i_upars_fn,
    design_matrix=design_matrix,
    y_da=y_da,
    offset_da=offset_da,
    factorial_term=factorial_term,
    coef_names=coef_names
)
```

### Computational considerations

While moment matching requires additional density evaluations compared to standard PSIS-LOO-CV, the computational cost remains modest. For each transformed draw $\theta^{*(s)}$, we must evaluate both the full-data posterior density $p(\theta^{*(s)} \mid y)$ and the likelihood $p(y_i \mid \theta^{*(s)})$, rather than just the likelihood as in standard PSIS. Even with multiple transformation iterations, this cost is substantially smaller than refitting the model for each problematic observation.

The key trade-off is between accuracy and computational efficiency. When several observations have high Pareto-$k$ values, moment matching provides reliable estimates at a fraction of the cost of exact PSIS-LOO-CV, making it practical for routine model assessment even with computationally expensive models. In our roaches example with 13 problematic observations, moment matching requires a few additional seconds of computation compared to minutes or hours that would be needed to refit the model 13 times.

### Running moment matching

With the required functions defined, we can now run PSIS-LOO-CV with importance weighted moment matching. We will specify that we want to match the covariance structure of the posterior draws given the complicated structure of the data. 

Keep in mind that the `split` argument, which specifies whether to use the split proposal density, is a boolean that defaults to `True`. This is highly recommended in most applied cases. When `split=True`, the split proposal density is

$$
g_{\text{split,loo}}(\theta) \propto p(\theta \mid y) + |\mathbf{J}_{T_w}|^{-1}\, p(T_w^{-1}(\theta) \mid y),
$$

so each fold mixes the full-data posterior with the transformed draws from the denominator adaptation.

```{python}
#| warning: false
loo_mm_result = azp.loo_moment_match(
    idata,
    loo_result,
    log_prob_upars_fn=log_prob_upars,
    log_lik_i_upars_fn=log_lik_i_upars,
    upars=upars,
    var_name="y",
    cov=True,
)

loo_mm_result
```

After moment matching, the Pareto-$k$ values improve substantially, with all 262 observations now having Pareto-$k$ values below 0.7. This indicates that moment matching has successfully resolved all problematic importance sampling issues, providing reliable PSIS-LOO-CV estimates for every observation. This represents a complete improvement over the original 13 problematic observations. Notably, the ELPD estimate decreases from -5461.14 to -5477.60 after moment matching, indicating that the original PSIS-LOO-CV estimate was too optimistic and `loo()` overestimated the predictive performance.

<!-- TODO: Add some commentary on n_eff_i and influence_pareto_k to compare mm pareto values with original pareto values, and to look at the per observation effective sample size and influence of the Pareto $k$ values. -->

## Summary

Importance weighted moment matching provides an efficient solution for improving PSIS-LOO-CV when influential observations lead to unreliable importance sampling approximations. Rather than refitting models, IWMM transforms existing posterior draws to match importance-weighted moments in the unconstrained parameter space. The approach is fully automated, requires no user tuning, and works with arbitrary posterior samples from probabilistic programming frameworks where density evaluation is possible.

The method has important limitations worth keeping in mind:

- It targets only first and second moments, so improvements depend on whether these moments adequately capture differences between proposal and target distributions
- When importance weights have large variance, the computation of weighted moments can become unreliable (mitigated through weight regularization or larger sample sizes)
- The algorithm may fail to find sufficiently helpful transformations when target and proposal distributions differ substantially in tail behavior, correlation structure, or number of modes
- For extremely high-dimensional problems, the most sophisticated transformation (matching full covariance) may become numerically unstable
- The split proposal approximation introduces some inefficiency by placing unnecessary probability mass in regions where the integrand is near its expectation, though this trade-off is least problematic precisely when adaptive methods are most needed

Despite these limitations, moment matching succeeds in most practical applications when the original posterior simulation was reasonably successful, providing both computational efficiency and improved reliability for model assessment without requiring complex tuning or auxiliary assumptions.
