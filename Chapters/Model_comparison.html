<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-04-02">

<title>7&nbsp; Model Comparison – Exploratory Analysis of Bayesian Models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Chapters/Model_comparison_large_data.html" rel="next">
<link href="../Chapters/Sensitivity_checks.html" rel="prev">
<link href="../favicon.ico" rel="icon">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark-4d9afe2b8d18ee9fa5d0d57b5ed4214d.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-7bf12d62aa84b4fa538b342f1416a45b.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark-691c43ad62c52d8f2a4cfbd07224d002.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../site_libs/bootstrap/bootstrap-7bf12d62aa84b4fa538b342f1416a45b.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="[[7]{.chapter-number}&nbsp; [Model Comparison]{.chapter-title}]{#sec-model-comparison .quarto-section-identifier}">
<meta name="citation_publication_date" content="2025-04-02">
<meta name="citation_cover_date" content="2025-04-02">
<meta name="citation_year" content="2025">
<meta name="citation_online_date" content="2025-04-02">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Graphical perception: Theory, experimentation, and application to the development of graphical methods;,citation_author=William S. Cleveland;,citation_author=Robert McGill;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_fulltext_html_url= https://www.tandfonline.com/doi/abs/10.1080/01621459.1984.10478080;,citation_issue=387;,citation_doi=10.1080/01621459.1984.10478080;,citation_volume=79;,citation_journal_title=Journal of the American Statistical Association;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Crowdsourcing graphical perception: Using mechanical turk to assess visualization design;,citation_author=Jeffrey Heer;,citation_author=Michael Bostock;,citation_publication_date=2010-04;,citation_cover_date=2010-04;,citation_year=2010;,citation_fulltext_html_url=https://doi.org/10.1145/1753326.1753357;,citation_doi=10.1145/1753326.1753357;,citation_isbn=978-1-60558-929-9;,citation_conference_title=Proceedings of the SIGCHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’10;">
<meta name="citation_reference" content="citation_title=Theories of Data Analysis: From Magical Thinking Through Classical Statistics;,citation_abstract=This chapter contains sections titled: Intuitive Statistics— Some Inferential Problems Multiplicity— A Pervasive Problem Some Remedies Theories for Data Analysis Uses for Mathematics In Defense of Controlled Magical Thinking;,citation_author=Persi Diaconis;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_doi=10.1002/9781118150702.ch1;,citation_isbn=978-1-118-15070-2;,citation_inbook_title=Exploring Data Tables, Trends, and Shapes;">
<meta name="citation_reference" content="citation_title=Probabilistic Machine Learning and Artificial Intelligence;,citation_abstract=How can a machine learn from experience? Probabilistic modelling provides a framework for understanding what learning is, and has therefore emerged as one of the principal theoretical and practical approaches for designing machines that learn from data acquired through experience. The probabilistic framework, which describes how to represent and manipulate uncertainty about models and predictions, has a central role in scientific data analysis, machine learning, robotics, cognitive science and artificial intelligence. This Review provides an introduction to this framework, and discusses some of the state-of-the-art advances in the field, namely, probabilistic programming, Bayesian optimization, data compression and automatic model discovery.;,citation_author=Zoubin Ghahramani;,citation_publication_date=2015-05;,citation_cover_date=2015-05;,citation_year=2015;,citation_issue=7553;,citation_doi=10.1038/nature14541;,citation_issn=0028-0836;,citation_volume=521;,citation_journal_title=Nature;">
<meta name="citation_reference" content="citation_title=Bayesian Programming;,citation_author=Pierre Bessiere;,citation_author=Emmanuel Mazer;,citation_author=Juan Manuel Ahuactzin;,citation_author=Kamel Mekhnacha;,citation_publication_date=2013-12;,citation_cover_date=2013-12;,citation_year=2013;,citation_fulltext_html_url=https://www.crcpress.com/Bayesian-Programming/Bessiere-Mazer-Ahuactzin-Mekhnacha/p/book/9781439880326;,citation_isbn=978-1-4398-8032-6;">
<meta name="citation_reference" content="citation_title=Probabilistic Programming;,citation_author=Daniel Roy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=http://probabilistic-programming.org;">
<meta name="citation_reference" content="citation_title=Xarray: N-D Labeled Arrays and Datasets in Python;,citation_author=Stephan Hoyer;,citation_author=Joe Hamman;,citation_publication_date=2017-04;,citation_cover_date=2017-04;,citation_year=2017;,citation_issue=1;,citation_doi=10.5334/jors.148;,citation_issn=2049-9647;,citation_volume=5;,citation_journal_title=Journal of Open Research Software;">
<meta name="citation_reference" content="citation_title=Visualizing count data regressions using rootograms;,citation_author=Christian Kleiber;,citation_author=Achim Zeileis;,citation_publication_date=2016-07;,citation_cover_date=2016-07;,citation_year=2016;,citation_fulltext_html_url=http://dx.doi.org/10.1080/00031305.2016.1173590;,citation_issue=3;,citation_doi=10.1080/00031305.2016.1173590;,citation_issn=1537-2731;,citation_volume=70;,citation_journal_title=The American Statistician;,citation_publisher=Informa UK Limited;">
<meta name="citation_reference" content="citation_title=Satellite male groups in horseshoe crabs, limulus polyphemus;,citation_author=H. Jane Brockmann;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1996.tb01099.x;,citation_issue=1;,citation_doi=10.1111/j.1439-0310.1996.tb01099.x;,citation_volume=102;,citation_journal_title=Ethology;">
<meta name="citation_reference" content="citation_title=Exploratory Data Analysis;,citation_author=John W. Tukey;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_fulltext_html_url=https://archive.org/details/exploratorydataa0000tuke_7616/mode/2up;,citation_isbn=978-0-201-07616-5;">
<meta name="citation_reference" content="citation_title=The separation plot: A new visual method for evaluating the fit of binary models;,citation_author=Brian Greenhill;,citation_author=Michael D. Ward;,citation_author=Audrey Sacks;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-5907.2011.00525.x;,citation_issue=4;,citation_doi=10.1111/j.1540-5907.2011.00525.x;,citation_volume=55;,citation_journal_title=American Journal of Political Science;">
<meta name="citation_reference" content="citation_title=Data analysis using regression and multilevel/hierarchical models;,citation_author=Andrew Gelman;,citation_author=Jennifer Hill;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_fulltext_html_url=https://sites.stat.columbia.edu/gelman/arm/;,citation_isbn=9780521867061;">
<meta name="citation_reference" content="citation_title=Detecting and diagnosing prior and likelihood sensitivity with power-scaling;,citation_author=Noa Kallioinen;,citation_author=Topi Paananen;,citation_author=Paul-Christian Bürkner;,citation_author=Aki Vehtari;,citation_publication_date=2023-12;,citation_cover_date=2023-12;,citation_year=2023;,citation_fulltext_html_url=https://doi.org/10.1007/s11222-023-10366-5;,citation_issue=1;,citation_doi=10.1007/s11222-023-10366-5;,citation_issn=1573-1375;,citation_volume=34;,citation_journal_title=Statistics and Computing;">
<meta name="citation_reference" content="citation_title=Graphical test for discrete uniformity and its applications in goodness-of-fit evaluation and multiple sample comparison;,citation_author=Teemu Säilynoja;,citation_author=Paul-Christian Bürkner;,citation_author=Aki Vehtari;,citation_publication_date=2022-03;,citation_cover_date=2022-03;,citation_year=2022;,citation_fulltext_html_url=https://doi.org/10.1007/s11222-022-10090-6;,citation_issue=2;,citation_doi=10.1007/s11222-022-10090-6;,citation_issn=1573-1375;,citation_volume=32;,citation_journal_title=Statistics and Computing;">
<meta name="citation_reference" content="citation_title=Validating bayesian inference algorithms with simulation-based calibration;,citation_author=Sean Talts;,citation_author=Michael Betancourt;,citation_author=Daniel Simpson;,citation_author=Aki Vehtari;,citation_author=Andrew Gelman;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/1804.06788;">
<meta name="citation_reference" content="citation_title=On thinning of chains in MCMC;,citation_author=William A. Link;,citation_author=Mitchell J. Eaton;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_fulltext_html_url=https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.2041-210X.2011.00131.x;,citation_issue=1;,citation_doi=10.1111/j.2041-210X.2011.00131.x;,citation_volume=3;,citation_journal_title=Methods in Ecology and Evolution;">
<meta name="citation_reference" content="citation_title=Subsampling the Gibbs Sampler;,citation_author=Steven N. MacEachern;,citation_author=L. Mark Berliner;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_fulltext_html_url=https://www.jstor.org/stable/2684714;,citation_issue=3;,citation_doi=10.2307/2684714;,citation_issn=0003-1305;,citation_volume=48;,citation_journal_title=The American Statistician;">
<meta name="citation_reference" content="citation_title=The Prior Can Often Only Be Understood in the Context of the Likelihood;,citation_author=Andrew Gelman;,citation_author=Daniel Simpson;,citation_author=Michael Betancourt;,citation_publication_date=2017-10;,citation_cover_date=2017-10;,citation_year=2017;,citation_fulltext_html_url=https://www.mdpi.com/1099-4300/19/10/555;,citation_issue=10;,citation_doi=10.3390/e19100555;,citation_issn=1099-4300;,citation_volume=19;,citation_journal_title=Entropy;">
<meta name="citation_reference" content="citation_title=Prior Knowledge Elicitation: The Past, Present, and Future;,citation_author=Petrus Mikkola;,citation_author=Osvaldo A. Martin;,citation_author=Suyog Chandramouli;,citation_author=Marcelo Hartmann;,citation_author=Oriol Abril Pla;,citation_author=Owen Thomas;,citation_author=Henri Pesonen;,citation_author=Jukka Corander;,citation_author=Aki Vehtari;,citation_author=Samuel Kaski;,citation_author=Paul-Christian Bürkner;,citation_author=Arto Klami;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1214/23-BA1381;,citation_issue=4;,citation_doi=10.1214/23-BA1381;,citation_volume=19;,citation_journal_title=Bayesian Analysis;,citation_publisher=International Society for Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Probability Theory: The Logic of Science;,citation_abstract=Going beyond the conventional mathematics of probability theory, this study views the subject in a wider context. It discusses new results, along with applications of probability theory to a variety of problems. The book contains many exercises and is suitable for use as a textbook on graduate-level courses involving data analysis. Aimed at readers already familiar with applied mathematics at an advanced undergraduate level or higher, it is of interest to scientists concerned with inference from incomplete information.;,citation_author=E. T. Jaynes;,citation_editor=G. Larry Bretthorst;,citation_publication_date=2003-06;,citation_cover_date=2003-06;,citation_year=2003;,citation_fulltext_html_url=https://bayes.wustl.edu/etj/prob/book.pdf;,citation_isbn=978-0-521-59271-0;">
<meta name="citation_reference" content="citation_title=PreliZ: A tool-box for prior elicitation;,citation_author=Alejandro Icazatti;,citation_author=Oriol Abril-Pla;,citation_author=Arto Klami;,citation_author=Osvaldo A Martin;,citation_publication_date=2023-09;,citation_cover_date=2023-09;,citation_year=2023;,citation_fulltext_html_url=https://joss.theoj.org/papers/10.21105/joss.05499;,citation_issue=89;,citation_doi=10.21105/joss.05499;,citation_volume=8;,citation_journal_title=Journal of Open Source Software;">
<meta name="citation_reference" content="citation_title=Bayesian workflow;,citation_author=Andrew Gelman;,citation_author=Aki Vehtari;,citation_author=Daniel Simpson;,citation_author=Charles C. Margossian;,citation_author=Bob Carpenter;,citation_author=Yuling Yao;,citation_author=Lauren Kennedy;,citation_author=Jonah Gabry;,citation_author=Paul-Christian Bürkner;,citation_author=Martin Modrák;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2011.01808;">
<meta name="citation_reference" content="citation_title=A web-based tool for eliciting probability distributions from experts;,citation_author=David E. Morris;,citation_author=Jeremy E. Oakley;,citation_author=John A. Crowe;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_fulltext_html_url=https://www.sciencedirect.com/science/article/pii/S1364815213002533;,citation_doi=10.1016/j.envsoft.2013.10.010;,citation_issn=1364-8152;,citation_volume=52;,citation_journal_title=Environmental Modelling &amp;amp;amp; Software;">
<meta name="citation_reference" content="citation_title=Bayesian Modeling and Computation in Python;,citation_author=Osvaldo A. Martin;,citation_author=Ravin Kumar;,citation_author=Junpeng Lao;,citation_publication_date=2021-12;,citation_cover_date=2021-12;,citation_year=2021;,citation_fulltext_html_url=https://bayesiancomputationbook.com/;,citation_isbn=978-0-367-89436-8;">
<meta name="citation_reference" content="citation_title=Bayesian Analysis with Python: A Practical Guide to probabilistic modeling, 3rd Edition;,citation_author=Osvaldo A Martin;,citation_publication_date=2024-02;,citation_cover_date=2024-02;,citation_year=2024;,citation_fulltext_html_url=https://bap.com.ar/;,citation_isbn=978-1-80512-716-1;">
<meta name="citation_reference" content="citation_title=BART: Bayesian additive regression trees;,citation_author=Hugh A. Chipman;,citation_author=Edward I. George;,citation_author=Robert E. McCulloch;,citation_publication_date=2010-03;,citation_cover_date=2010-03;,citation_year=2010;,citation_fulltext_html_url=http://projecteuclid.org/euclid.aoas/1273584455;,citation_issue=1;,citation_doi=10.1214/09-AOAS285;,citation_issn=1932-6157;,citation_volume=4;,citation_journal_title=The Annals of Applied Statistics;">
<meta name="citation_reference" content="citation_title=Practical bayesian model evaluation using leave-one-out cross-validation and WAIC;,citation_author=Aki Vehtari;,citation_author=Andrew Gelman;,citation_author=Jonah Gabry;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://doi.org/10.1007/s11222-016-9696-4;,citation_issue=5;,citation_doi=10.1007/s11222-016-9696-4;,citation_volume=27;,citation_journal_title=Statistics and Computing;">
<meta name="citation_reference" content="citation_title=Using Stacking to Average Bayesian Predictive Distributions (with Discussion);,citation_author=Yuling Yao;,citation_author=Aki Vehtari;,citation_author=Daniel Simpson;,citation_author=Andrew Gelman;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1214/17-BA1091;,citation_issue=3;,citation_doi=10.1214/17-BA1091;,citation_volume=13;,citation_journal_title=Bayesian Analysis;,citation_publisher=International Society for Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=A Widely Applicable Bayesian Information Criterion;,citation_author=Sumio Watanabe;,citation_publication_date=2013-03;,citation_cover_date=2013-03;,citation_year=2013;,citation_fulltext_html_url=https://dl.acm.org/doi/10.5555/2567709.2502609;,citation_volume=14;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=A new look at the statistical model identification;,citation_author=H. Akaike;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_issue=6;,citation_doi=10.1109/TAC.1974.1100705;,citation_volume=19;,citation_journal_title=IEEE Transactions on Automatic Control;">
<meta name="citation_reference" content="citation_title=Rank-Normalization, Folding, and Localization: An Improved $\widehat{R}$ for Assessing Convergence of MCMC (with Discussion);,citation_author=Aki Vehtari;,citation_author=Andrew Gelman;,citation_author=Daniel Simpson;,citation_author=Bob Carpenter;,citation_author=Paul-Christian Bürkner;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_fulltext_html_url=https://doi.org/10.1214/20-BA1221;,citation_issue=2;,citation_doi=10.1214/20-BA1221;,citation_volume=16;,citation_journal_title=Bayesian Analysis;,citation_publisher=International Society for Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Truncated importance sampling;,citation_author=Edward L. Ionides;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_doi=10.1198/106186008X320465;,citation_volume=17;,citation_journal_title=Journal of Computational and Graphical Statistics;">
<meta name="citation_reference" content="citation_title=No unbiased estimator of the variance of k-fold cross-validation;,citation_author=Yoshua Bengio;,citation_author=Yves Grandvalet;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_fulltext_html_url=https://jmlr.csail.mit.edu/papers/v5/grandvalet04a.html;,citation_volume=5;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=On the theory of sampling from finite populations;,citation_author=Morris H. Hansen;,citation_author=William N. Hurwitz;,citation_publication_date=1943;,citation_cover_date=1943;,citation_year=1943;,citation_issue=4;,citation_doi=10.1214/aoms/1177731360;,citation_volume=14;,citation_journal_title=The Annals of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bayesian leave-one-out cross-validation for large data;,citation_author=Måns Magnusson;,citation_author=Michael Andersen;,citation_author=Johan Jonasson;,citation_author=Aki Vehtari;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://proceedings.mlr.press/v97/magnusson19a.html;,citation_volume=97;,citation_conference_title=Proceedings of the 36th international conference on machine learning;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Leave-one-out cross-validation for model comparison in large data;,citation_author=Måns Magnusson;,citation_author=Michael Riis Andersen;,citation_author=Johan Jonasson;,citation_author=Aki Vehtari;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/2001.00980;,citation_volume=108;,citation_conference_title=Proceedings of the 23rd international conference on artificial intelligence and statistics;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Projective inference in high-dimensional problems: Prediction and feature selection;,citation_author=Juho Piironen;,citation_author=Markus Paasiniemi;,citation_author=Aki Vehtari;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://doi.org/10.1214/20-EJS1711;,citation_issue=1;,citation_doi=10.1214/20-EJS1711;,citation_volume=14;,citation_journal_title=Electronic Journal of Statistics;,citation_publisher=Institute of Mathematical Statistics; Bernoulli Society;">
<meta name="citation_reference" content="citation_title=Bayesian additive regression trees for probabilistic programming;,citation_author=Miriana Quiroga;,citation_author=Pablo G Garay;,citation_author=Juan M. Alonso;,citation_author=Juan Martin Loyola;,citation_author=Osvaldo A Martin;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://arxiv.org/abs/2206.03619;,citation_doi=10.48550/ARXIV.2206.03619;,citation_publisher=arXiv;">
<meta name="citation_reference" content="citation_title=Robust and efficient projection predictive inference;,citation_author=Yann McLatchie;,citation_author=Sölvi Rögnvaldsson;,citation_author=Frank Weber;,citation_author=Aki Vehtari;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2306.15581;">
<meta name="citation_reference" content="citation_title=Implicitly adaptive importance sampling;,citation_author=Topi Paananen;,citation_author=Juho Piironen;,citation_author=Paul-Christian Bürkner;,citation_author=Aki Vehtari;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://arxiv.org/abs/1906.08850;">
<meta name="citation_reference" content="citation_title=Fitting percentage of body fat to simple body measurements;,citation_author=Roger W. Johnson;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_fulltext_html_url=https://doi.org/10.1080/10691898.1996.11910505;,citation_issue=1;,citation_doi=10.1080/10691898.1996.11910505;,citation_volume=4;,citation_journal_title=Journal of Statistics Education;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Non-parametric jensen-shannon divergence;,citation_author=Hoang-Vu Nguyen;,citation_author=Jilles Vreeken;,citation_editor=Annalisa Appice;,citation_editor=Pedro Pereira Rodrigues;,citation_editor=Vítor Santos Costa;,citation_editor=João Gama;,citation_editor=Alípio Jorge;,citation_editor=Carlos Soares;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://doi.org/10.1007/978-3-319-23525-7_11;,citation_doi=10.1007/978-3-319-23525-7_11;,citation_conference_title=Machine learning and knowledge discovery in databases;,citation_conference=Springer International Publishing;">
<meta name="citation_reference" content="citation_title=Modern Applied Statistics with S;,citation_author=W. N. Venables;,citation_author=B. D. Ripley;,citation_publication_date=2002-08;,citation_cover_date=2002-08;,citation_year=2002;,citation_fulltext_html_url=https://doi.org/10.1007/978-0-387-21706-2;,citation_doi=10.1007/978-0-387-21706-2;,citation_isbn=978-0-387-95457-8;">
<meta name="citation_reference" content="citation_title=Satellite male groups in horseshoe crabs, limulus polyphemus;,citation_author=H. Jane Brockmann;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_fulltext_html_url=https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1439-0310.1996.tb01099.x;,citation_issue=1;,citation_doi=10.1111/j.1439-0310.1996.tb01099.x;,citation_volume=102;,citation_journal_title=Ethology;">
<meta name="citation_reference" content="citation_title=Recommendations for visual predictive checks in bayesian workflow;,citation_author=Teemu Säilynoja;,citation_author=Andrew R. Johnson;,citation_author=Osvaldo A. Martin;,citation_author=Aki Vehtari;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2503.01509;">
<meta name="citation_reference" content="citation_title=Visualization in bayesian workflow;,citation_author=Jonah Gabry;,citation_author=Daniel Simpson;,citation_author=Aki Vehtari;,citation_author=Michael Betancourt;,citation_author=Andrew Gelman;,citation_publication_date=2019-01;,citation_cover_date=2019-01;,citation_year=2019;,citation_fulltext_html_url=https://doi.org/10.1111/rssa.12378;,citation_issue=2;,citation_doi=10.1111/rssa.12378;,citation_issn=0964-1998;,citation_volume=182;,citation_journal_title=Journal of the Royal Statistical Society Series A: Statistics in Society;">
<meta name="citation_reference" content="citation_title=Posterior Predictive $p$-Values;,citation_author=Xiao-Li Meng;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_fulltext_html_url=https://doi.org/10.1214/aos/1176325622;,citation_issue=3;,citation_doi=10.1214/aos/1176325622;,citation_volume=22;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Bayesian Data Analysis;,citation_author=Andrew Gelman;,citation_author=John B. Carlin;,citation_author=Hal S. Stern;,citation_author=David B. Dunson;,citation_author=Aki Vehtari;,citation_author=Donald B. Rubin;,citation_publication_date=2013-11;,citation_cover_date=2013-11;,citation_year=2013;,citation_fulltext_html_url=https://doi.org/10.1201/b16018;,citation_isbn=978-1-4398-4095-5;">
<meta name="citation_reference" content="citation_title=Two simple examples for understanding posterior p-values whose distributions are far from uniform;,citation_author=Andrew Gelman;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_fulltext_html_url=https://doi.org/10.1214/13-EJS854;,citation_issue=none;,citation_doi=10.1214/13-EJS854;,citation_volume=7;,citation_journal_title=Electronic Journal of Statistics;,citation_publisher=Institute of Mathematical Statistics; Bernoulli Society;">
<meta name="citation_reference" content="citation_title=Stable reliability diagrams for probabilistic classifiers;,citation_author=Timo Dimitriadis;,citation_author=Tilmann Gneiting;,citation_author=Alexander I. Jordan;,citation_publication_date=2021-02;,citation_cover_date=2021-02;,citation_year=2021;,citation_fulltext_html_url=https://www.pnas.org/doi/abs/10.1073/pnas.2016191118;,citation_issue=8;,citation_doi=10.1073/pnas.2016191118;,citation_volume=118;,citation_journal_title=Proceedings of the National Academy of Sciences;">
<meta name="citation_reference" content="citation_title=An Empirical Distribution Function for Sampling with Incomplete Information;,citation_author=Miriam Ayer;,citation_author=H. D. Brunk;,citation_author=G. M. Ewing;,citation_author=W. T. Reid;,citation_author=Edward Silverman;,citation_publication_date=1955;,citation_cover_date=1955;,citation_year=1955;,citation_fulltext_html_url=https://doi.org/10.1214/aoms/1177728423;,citation_issue=4;,citation_doi=10.1214/aoms/1177728423;,citation_volume=26;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Prior knowledge elicitation: The past, present, and future;,citation_author=Petrus Mikkola;,citation_author=Osvaldo A. Martin;,citation_author=Suyog Chandramouli;,citation_author=Marcelo Hartmann;,citation_author=Oriol Abril Pla;,citation_author=Owen Thomas;,citation_author=Henri Pesonen;,citation_author=Jukka Corander;,citation_author=Aki Vehtari;,citation_author=Samuel Kaski;,citation_author=Paul-Christian Bürkner;,citation_author=Arto Klami;,citation_publication_date=2024-12;,citation_cover_date=2024-12;,citation_year=2024;,citation_issue=4;,citation_doi=10.1214/23-BA1381;,citation_volume=19;,citation_journal_title=Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Validation of software for bayesian models using posterior quantiles;,citation_author=Samantha R Cook;,citation_author=Andrew Gelman;,citation_author=Donald B Rubin and;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_fulltext_html_url=https://doi.org/10.1198/106186006X136976;,citation_issue=3;,citation_doi=10.1198/106186006X136976;,citation_volume=15;,citation_journal_title=Journal of Computational and Graphical Statistics;,citation_publisher=ASA Website;">
<meta name="citation_reference" content="citation_title=Simulation-Based Calibration Checking for Bayesian Computation: The Choice of Test Quantities Shapes Sensitivity;,citation_author=Martin Modrák;,citation_author=Angie H. Moon;,citation_author=Shinyoung Kim;,citation_author=Paul Bürkner;,citation_author=Niko Huurre;,citation_author=Kateřina Faltejsková;,citation_author=Andrew Gelman;,citation_author=Aki Vehtari;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://doi.org/10.1214/23-BA1404;,citation_issue=2;,citation_doi=10.1214/23-BA1404;,citation_volume=20;,citation_journal_title=Bayesian Analysis;,citation_publisher=International Society for Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Diagnosing suboptimal cotangent disintegrations in hamiltonian monte carlo;,citation_author=Michael Betancourt;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_fulltext_html_url=https://arxiv.org/abs/1604.00695;">
<meta name="citation_reference" content="citation_title=Posterior SBC: Simulation-based calibration checking conditional on data;,citation_author=Teemu Säilynoja;,citation_author=Marvin Schmitt;,citation_author=Paul-Christian Bürkner;,citation_author=Aki Vehtari;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2502.03279;">
<meta name="citation_reference" content="citation_title=Bayesian Analysis Reporting Guidelines;,citation_author=John K. Kruschke;,citation_publication_date=2021-10;,citation_cover_date=2021-10;,citation_year=2021;,citation_fulltext_html_url=https://www.nature.com/articles/s41562-021-01177-7;,citation_issue=10;,citation_doi=10.1038/s41562-021-01177-7;,citation_issn=2397-3374;,citation_volume=5;,citation_journal_title=Nature Human Behaviour;">
<meta name="citation_reference" content="citation_title=A call for changing data analysis practices: From philosophy and comprehensive reporting to modeling approaches and back;,citation_author=Osvaldo A. Martin;,citation_author=François P. Teste;,citation_publication_date=2022-07;,citation_cover_date=2022-07;,citation_year=2022;,citation_fulltext_html_url=https://doi.org/10.1007/s11104-022-05329-0;,citation_issue=1;,citation_doi=10.1007/s11104-022-05329-0;,citation_issn=1573-5036;,citation_volume=476;,citation_journal_title=Plant and Soil;">
<meta name="citation_reference" content="citation_title=Handbook of Markov Chain Monte Carlo;,citation_editor=Steve Brooks;,citation_editor=Andrew Gelman;,citation_editor=Galin Jones;,citation_editor=Xiao-Li Meng;,citation_publication_date=2011-05;,citation_cover_date=2011-05;,citation_year=2011;,citation_fulltext_html_url=https://doi.org/10.1201/b10905;,citation_isbn=978-1-4200-7941-8;">
<meta name="citation_reference" content="citation_title=Handbook of Bayesian Variable Selection;,citation_editor=Mahlet G. Tadesse;,citation_editor=Marina Vannucci;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_fulltext_html_url=https://doi.org/10.1201/9781003089018;,citation_isbn=978-0-367-54376-1;">
<meta name="citation_reference" content="citation_title=Think Stats: Exploratory Data Analysis;,citation_author=Allen B. Downey;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://allendowney.github.io/ThinkStats/;,citation_isbn=978-1-09-819025-5;">
<meta name="citation_reference" content="citation_title=Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures;,citation_author=Claus O. Wilke;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://clauswilke.com/dataviz/;,citation_isbn=978-1-4920-3108-6;">
<meta name="citation_reference" content="citation_title=Data Visualization: A Practical Introduction;,citation_author=Kieran Healy;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=https://kieranhealy.org/publications/dataviz/;,citation_isbn=978-0-691-18162-2;">
<meta name="citation_reference" content="citation_title=Getting (more out of) Graphics: Practice and Principles of Data Visualisation;,citation_author=Antony Unwin;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://doi.org/10.1201/9781003131212;,citation_isbn=978-1-04-003556-6;">
<meta name="citation_reference" content="citation_title=When (ish) is My Bus? User-centered Visualizations of Uncertainty in Everyday, Mobile Predictive Systems;,citation_author=Matthew Kay;,citation_author=Tara Kola;,citation_author=Jessica R. Hullman;,citation_author=Sean A. Munson;,citation_publication_date=2016-05;,citation_cover_date=2016-05;,citation_year=2016;,citation_fulltext_html_url=https://doi.org/10.1145/2858036.2858558;,citation_doi=10.1145/2858036.2858558;,citation_isbn=978-1-4503-3362-7;,citation_conference_title=Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’16;">
<meta name="citation_reference" content="citation_title=Dot Plots;,citation_author=Leland Wilkinson;,citation_publication_date=1999-08;,citation_cover_date=1999-08;,citation_year=1999;,citation_fulltext_html_url=https://www.tandfonline.com/doi/abs/10.1080/00031305.1999.10474474;,citation_issue=3;,citation_doi=10.1080/00031305.1999.10474474;,citation_issn=0003-1305;,citation_volume=53;,citation_journal_title=The American Statistician;">
<meta name="citation_reference" content="citation_title=Uncertainty Displays Using Quantile Dotplots or CDFs Improve Transit Decision-Making;,citation_author=Michael Fernandes;,citation_author=Logan Walls;,citation_author=Sean Munson;,citation_author=Jessica Hullman;,citation_author=Matthew Kay;,citation_publication_date=2018-04;,citation_cover_date=2018-04;,citation_year=2018;,citation_fulltext_html_url=https://doi.org/10.1145/3173574.3173718;,citation_doi=10.1145/3173574.3173718;,citation_isbn=978-1-4503-5620-6;,citation_conference_title=Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems;,citation_conference=Association for Computing Machinery;,citation_series_title=CHI ’18;">
<meta name="citation_reference" content="citation_title=The book of statistical proofs;,citation_author=Joram Soch;,citation_author=Thomas J Faulkenberry;,citation_author=Kenneth Petrykowski;,citation_author=Carsten Allefeld;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://statproofbook.github.io/;,citation_doi=10.5281/ZENODO.4305949;">
<meta name="citation_reference" content="citation_title=Predictive assessment and comparison of bayesian survival models for cancer recurrence;,citation_author=Saku Suorsa;,citation_author=Aki Vehtari;,citation_publication_date=2026;,citation_cover_date=2026;,citation_year=2026;,citation_fulltext_html_url=https://arxiv.org/abs/2601.01662;">
<meta name="citation_reference" content="citation_title=Statistical Rethinking: A Bayesian Course with Examples in R and STAN;,citation_author=Richard McElreath;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_fulltext_html_url=https://doi.org/10.1201/9780429029608;,citation_isbn=978-0-367-13991-9;">
</head>

<body class="nav-sidebar docked quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Chapters/Model_comparison.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Model Comparison</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Exploratory Analysis of Bayesian Models</a> 
        <div class="sidebar-tools-main tools-wide">
    <div class="dropdown">
      <a href="" title="github" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="github"><i class="bi bi-github"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/arviz-devs/Exploratory-Analysis-of-Bayesian-Models">
            source
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="https://github.com/arviz-devs/Exploratory-Analysis-of-Bayesian-Models/issues/new">
            issues
            </a>
          </li>
      </ul>
    </div>
    <a href="https://numfocus.org/donate-to-arviz" title="donations" class="quarto-navigation-tool px-1" aria-label="donations"><i class="bi bi-coin"></i></a>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">‎</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Elements_of_visualization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Elements of Visualization</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/DataTree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Working with DataTree</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Random Variables, Distributions, and Uncertainty</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/MCMC_diagnostics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">MCMC Diagnostics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Prior_posterior_predictive_checks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Prior and Posterior predictive checks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Sensitivity_checks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Prior and likelihood sensitivity checks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Model_comparison.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Model Comparison</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Model_comparison_large_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Model Comparison for Large Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Moment_Matching.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Moment matching for improved PSIS-LOO-CV</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Case_study_model_comparison.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model Comparison (case study)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Variable_selection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Variable Selection</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Prior_elicitation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Prior Elicitation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Simulation_based_calibration.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Simulation-based calibration checking</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Presenting_results.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Presentation of Results</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/Bayesian_workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Bayesian Workflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Chapters/References.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">7.1</span> Overview</a></li>
  <li><a href="#the-balance-between-simplicity-and-accuracy" id="toc-the-balance-between-simplicity-and-accuracy" class="nav-link" data-scroll-target="#the-balance-between-simplicity-and-accuracy"><span class="header-section-number">7.2</span> The balance between simplicity and accuracy</a>
  <ul class="collapse">
  <li><a href="#predictive-accuracy-measures" id="toc-predictive-accuracy-measures" class="nav-link" data-scroll-target="#predictive-accuracy-measures"><span class="header-section-number">7.2.1</span> Predictive accuracy measures</a></li>
  </ul></li>
  <li><a href="#cross-validation" id="toc-cross-validation" class="nav-link" data-scroll-target="#cross-validation"><span class="header-section-number">7.3</span> Cross validation</a></li>
  <li><a href="#information-criteria" id="toc-information-criteria" class="nav-link" data-scroll-target="#information-criteria"><span class="header-section-number">7.4</span> Information criteria</a>
  <ul class="collapse">
  <li><a href="#entropy" id="toc-entropy" class="nav-link" data-scroll-target="#entropy"><span class="header-section-number">7.4.1</span> Entropy</a></li>
  <li><a href="#sec-kl-divergence" id="toc-sec-kl-divergence" class="nav-link" data-scroll-target="#sec-kl-divergence"><span class="header-section-number">7.4.2</span> KL divergence</a></li>
  <li><a href="#akaike-information-criterion" id="toc-akaike-information-criterion" class="nav-link" data-scroll-target="#akaike-information-criterion"><span class="header-section-number">7.4.3</span> Akaike information criterion</a></li>
  <li><a href="#elpd" id="toc-elpd" class="nav-link" data-scroll-target="#elpd"><span class="header-section-number">7.4.4</span> ELPD</a></li>
  <li><a href="#waic" id="toc-waic" class="nav-link" data-scroll-target="#waic"><span class="header-section-number">7.4.5</span> WAIC</a></li>
  </ul></li>
  <li><a href="#sec-efficient-loo-cv" id="toc-sec-efficient-loo-cv" class="nav-link" data-scroll-target="#sec-efficient-loo-cv"><span class="header-section-number">7.5</span> Efficient LOO-CV</a>
  <ul class="collapse">
  <li><a href="#importance-sampling" id="toc-importance-sampling" class="nav-link" data-scroll-target="#importance-sampling"><span class="header-section-number">7.5.1</span> Importance Sampling</a></li>
  <li><a href="#importance-sampling-and-loo-cv" id="toc-importance-sampling-and-loo-cv" class="nav-link" data-scroll-target="#importance-sampling-and-loo-cv"><span class="header-section-number">7.5.2</span> Importance sampling and LOO-CV</a></li>
  </ul></li>
  <li><a href="#psis-loo-cv-in-arviz" id="toc-psis-loo-cv-in-arviz" class="nav-link" data-scroll-target="#psis-loo-cv-in-arviz"><span class="header-section-number">7.6</span> PSIS-LOO-CV in Arviz</a>
  <ul class="collapse">
  <li><a href="#pareto-k-and-loo-diagnostics" id="toc-pareto-k-and-loo-diagnostics" class="nav-link" data-scroll-target="#pareto-k-and-loo-diagnostics"><span class="header-section-number">7.6.1</span> Pareto k and LOO diagnostics</a></li>
  </ul></li>
  <li><a href="#sec-IWMM-theory" id="toc-sec-IWMM-theory" class="nav-link" data-scroll-target="#sec-IWMM-theory"><span class="header-section-number">7.7</span> When Pareto k values are too high</a>
  <ul class="collapse">
  <li><a href="#monte-carlo-estimators" id="toc-monte-carlo-estimators" class="nav-link" data-scroll-target="#monte-carlo-estimators"><span class="header-section-number">7.7.1</span> Monte Carlo estimators</a></li>
  <li><a href="#multiple-importance-sampling" id="toc-multiple-importance-sampling" class="nav-link" data-scroll-target="#multiple-importance-sampling"><span class="header-section-number">7.7.2</span> Multiple importance sampling</a></li>
  <li><a href="#importance-weighted-moment-matching" id="toc-importance-weighted-moment-matching" class="nav-link" data-scroll-target="#importance-weighted-moment-matching"><span class="header-section-number">7.7.3</span> Importance weighted moment matching</a></li>
  </ul></li>
  <li><a href="#sec-subsampledloo-theory" id="toc-sec-subsampledloo-theory" class="nav-link" data-scroll-target="#sec-subsampledloo-theory"><span class="header-section-number">7.8</span> When the dataset is too large</a>
  <ul class="collapse">
  <li><a href="#from-loo-to-subsampled-loo" id="toc-from-loo-to-subsampled-loo" class="nav-link" data-scroll-target="#from-loo-to-subsampled-loo"><span class="header-section-number">7.8.1</span> From LOO to subsampled LOO</a></li>
  <li><a href="#model-comparison-for-large-data" id="toc-model-comparison-for-large-data" class="nav-link" data-scroll-target="#model-comparison-for-large-data"><span class="header-section-number">7.8.2</span> Model comparison for large data</a></li>
  <li><a href="#previous-approaches-and-practical-limitations" id="toc-previous-approaches-and-practical-limitations" class="nav-link" data-scroll-target="#previous-approaches-and-practical-limitations"><span class="header-section-number">7.8.3</span> Previous approaches and practical limitations</a></li>
  <li><a href="#difference-estimator-for-large-data" id="toc-difference-estimator-for-large-data" class="nav-link" data-scroll-target="#difference-estimator-for-large-data"><span class="header-section-number">7.8.4</span> Difference estimator for large data</a></li>
  <li><a href="#fast-loo-surrogates" id="toc-fast-loo-surrogates" class="nav-link" data-scroll-target="#fast-loo-surrogates"><span class="header-section-number">7.8.5</span> Fast LOO surrogates</a></li>
  <li><a href="#asymptotic-guarantees-and-assumptions" id="toc-asymptotic-guarantees-and-assumptions" class="nav-link" data-scroll-target="#asymptotic-guarantees-and-assumptions"><span class="header-section-number">7.8.6</span> Asymptotic guarantees and assumptions</a></li>
  </ul></li>
  <li><a href="#absolute-metrics" id="toc-absolute-metrics" class="nav-link" data-scroll-target="#absolute-metrics"><span class="header-section-number">7.9</span> Absolute metrics</a>
  <ul class="collapse">
  <li><a href="#loo-expectations-and-metrics" id="toc-loo-expectations-and-metrics" class="nav-link" data-scroll-target="#loo-expectations-and-metrics"><span class="header-section-number">7.9.1</span> LOO expectations and metrics</a></li>
  <li><a href="#loo-pit" id="toc-loo-pit" class="nav-link" data-scroll-target="#loo-pit"><span class="header-section-number">7.9.2</span> LOO-PIT</a></li>
  </ul></li>
  <li><a href="#other-information-criteria" id="toc-other-information-criteria" class="nav-link" data-scroll-target="#other-information-criteria"><span class="header-section-number">7.10</span> Other information criteria</a></li>
  <li><a href="#bayes-factors" id="toc-bayes-factors" class="nav-link" data-scroll-target="#bayes-factors"><span class="header-section-number">7.11</span> Bayes factors</a>
  <ul class="collapse">
  <li><a href="#some-observations" id="toc-some-observations" class="nav-link" data-scroll-target="#some-observations"><span class="header-section-number">7.11.1</span> Some observations</a></li>
  <li><a href="#calculation-of-bayes-factors" id="toc-calculation-of-bayes-factors" class="nav-link" data-scroll-target="#calculation-of-bayes-factors"><span class="header-section-number">7.11.2</span> Calculation of Bayes factors</a></li>
  <li><a href="#savagedickey-ratio" id="toc-savagedickey-ratio" class="nav-link" data-scroll-target="#savagedickey-ratio"><span class="header-section-number">7.11.3</span> Savage–Dickey ratio</a></li>
  <li><a href="#bayes-factors-vs-the-alternatives" id="toc-bayes-factors-vs-the-alternatives" class="nav-link" data-scroll-target="#bayes-factors-vs-the-alternatives"><span class="header-section-number">7.11.4</span> Bayes factors vs the alternatives</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-model-comparison" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Model Comparison</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 2, 2025</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">February 6, 2026</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="overview" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">7.1</span> Overview</h2>
<p>Models are designed as approximations to help us understand a specific problem or a related class of problems. They are not intended to be exact replicas of the real world. In this sense, all models are “wrong.” However, not all models are equally wrong, some are better suited to particular aspects of a problem. For example, a model that is good for high-temperature observations may perform poorly for low-temperature observations.</p>
<p>In a typical data analysis, it’s common to develop multiple models that fit the same data. These models may differ in aspects such as priors, likelihoods, linear versus nonlinear terms, interactions terms, etc. When several plausible models are available, a key question arises: how should we choose between them?</p>
<p>Understanding the goals of the analysis and the problem at hand often provides valuable guidance. Models rarely incorporate all of our prior knowledge, so this additional information can help us evaluate and compare them. Prior and posterior predictive checks (see <a href="Prior_posterior_predictive_checks.html" class="quarto-xref"><span>Chapter 5</span></a>) and computational diagnostics (see <a href="MCMC_diagnostics.html" class="quarto-xref"><span>Chapter 4</span></a>) can further inform model choice (a model we can not fit well is a model we can not trust!). Even convention and tradition may influence selection, although scientific reasoning should ideally prevail over tradition.</p>
<p>In this chapter, we provided a theoretical, yet accesible, foundation for a series of methods for efficient model comparison. Later in <a href="Model_comparison_large_data.html" class="quarto-xref"><span>Chapter 8</span></a>, <a href="Case_study_model_comparison.html" class="quarto-xref"><span>Chapter 10</span></a>, and <a href="Moment_Matching.html" class="quarto-xref"><span>Chapter 9</span></a> we provided applied examples of these methods.</p>
</section>
<section id="the-balance-between-simplicity-and-accuracy" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="the-balance-between-simplicity-and-accuracy"><span class="header-section-number">7.2</span> The balance between simplicity and accuracy</h2>
<p>When comparing models, we seek a balance between simplicity and accuracy. Occam’s razor suggests that, among equally plausible explanations, the simplest should be preferred. In modeling, simplicity is often measured by the number of parameters, while accuracy reflects how well a model fits the data. Ideally, we want models that fit the data well without overfitting.</p>
<p>Overfitting occurs when a model captures not only the underlying patterns but also random noise. Such models perform well on the data used for fitting (within-sample error) but poorly on new, unseen data. Overfitting is more likely in highly flexible models with many parameters or when the model structure is overly complex. Detecting it requires evaluating performance on data not used for fitting, motivating out-of-sample measures such as cross-validation or information criteria.</p>
<p>Bayesian models are generally less prone to overfitting than many alternative approaches. This is because priors constrain the parameter space, and computing the posterior involves averaging over these priors rather than committing to a single point estimate. As a result, even highly flexible Bayesian models often avoid the extreme overfitting seen in classical settings. A typical text book example of overfitting is a polynomial with as many degrees of freedom as data points. This will indeed badly overfit under optimization-based methods, but a Bayesian model with even quite vague priors will provide a reasonable solution. Priors can even stabilize models with more parameters than observations, and for decades we have known that Bayesian methods can handle models with infinitely many parameters, such as Gaussian processes. However, this protection is not automatic. Bayesian models with very vague priors are more prone to overfitting, while models whose priors induce a prior predictive distribution consistent with domain knowledge tend to be more resistant to it.</p>
<section id="predictive-accuracy-measures" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="predictive-accuracy-measures"><span class="header-section-number">7.2.1</span> Predictive accuracy measures</h3>
<p>Evaluating a model only on the data used to fit it usually gives an overly optimistic view of its performance, a problem known as <strong>overfitting</strong>. Instead we prefer to evaluate a model in terms of its predictive accuracy, i.e.&nbsp;it’s capacity to predicte unobserved data.</p>
<p>The simplest way to do this is to use separate training and test datasets. But in practice, data is often limited, and setting aside part of it can be wasteful. Because this situation is so common, many methods have been developed to estimate predictive accuracy without <em>wasting</em> data.</p>
<p>We will focus on two families of methods:</p>
<ul>
<li><strong>Cross-validation</strong>: Divides the data into subsets that are alternately used for fitting and evaluation, effectively simulating a hold-out set while still using all data for inference.</li>
<li><strong>Information criteria</strong>: Approximate out-of-sample accuracy by combining in-sample fit with a penalty for model complexity.</li>
</ul>
</section>
</section>
<section id="cross-validation" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="cross-validation"><span class="header-section-number">7.3</span> Cross validation</h2>
<p>Cross-validation is a simple and, in most cases, effective solution for comparing models. We take our data and divide it into <span class="math inline">\(K\)</span> slices. We try to keep the portions more or less the same (in size and sometimes also in other characteristics, such as an equal number of classes). We then use <span class="math inline">\(K-1\)</span> portions to train the model and the rest to evaluate it. This process is systematically repeated, leaving, for each iteration, a different portion out of the training set and using that portion as the evaluation set. This is repeated until we have completed <span class="math inline">\(K\)</span> rounds of adjustment–evaluation. The accuracy of the model will be the average over the <span class="math inline">\(K\)</span> rounds. This is known as <span class="math inline">\(K\)</span>-fold cross-validation. Finally, once we have cross-validated, we use all the data to fit our model, and this is the model that is used to make predictions or for any other purpose.</p>
<p><img src="../img/cv.png" width="500"></p>
<p>When <span class="math inline">\(K\)</span> is equal to the number of data points, we get what is known as leave-one-out cross-validation (LOO-CV).</p>
<p>Cross validation is a routine practice in machine learning. And we have barely described the most essential aspects of this practice. For more information you can read <a href="http://themlbook.com/">The Hundred-Page Machine Learning Book</a> or <a href="https://www.amazon.com/Python-Machine-Learning-scikit-learn-TensorFlow-ebook/dp/B0742K7HYF">Python Machine Learning</a>, by Sebastian Raschka.</p>
<p>One downside of cross-validation is that it is computationally expensive. We need to fit the model <span class="math inline">\(K\)</span> times, and if we have a large dataset, this can be very expensive. But lucky us, by being Bayesian we can approximately compute LOO-CV in a very fast way, as discussed later in <a href="#sec-efficient-loo-cv" class="quarto-xref"><span>Section 7.5</span></a>. But before that we are going to discuss information criteria, because as we will see LOO-CV is actually related to these methods.</p>
</section>
<section id="information-criteria" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="information-criteria"><span class="header-section-number">7.4</span> Information criteria</h2>
<p>Information criteria are a collection of closely related tools used to compare models in terms of goodness of fit and model complexity. In other words, information criteria formalize the intuition we developed at the beginning of the chapter. The exact way these quantities are derived has to do with a field known as <a href="http://www.inference.org.uk/mackay/itila/book.html">Information Theory</a>.</p>
<p>An intuitive way to measure how well a model fits the data is to calculate the root mean square error between the data and the predictions made by the model:</p>
<p><span class="math display">\[
\frac{1}{N} \sum _{i}^{N} (y_i - \operatorname{E} (y_i \mid \theta))^2
\]</span></p>
<p><span class="math inline">\(\operatorname{E} (y_i \mid \theta)\)</span> is the predicted value given the estimated parameters. It is important to note that this is essentially the average of the difference between the observed and predicted data. Taking the square of the errors ensures that differences do not cancel out and emphasizes larger errors compared to other alternatives such as calculating the absolute value.</p>
<p>The mean square error may be familiar to us since it is very popular. But if we stop and reflect on this quantity we will see that in principle there is nothing special about it and we could well come up with more general expressions. In order to do that we are going to first discuss to two useful concepts, entropy and the Kulback-Leibler divergence.</p>
<section id="entropy" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="entropy"><span class="header-section-number">7.4.1</span> Entropy</h3>
<p>For a probability distribution with <span class="math inline">\(N\)</span> possible different events which each possible event having probability <span class="math inline">\(p_i\)</span>, the entropy is defined as:</p>
<p><span class="math display">\[
H(p) = - \mathbb{E}[\log{p}] = -\sum_i^N p_i \log{p_i}
\]</span></p>
<p>Entropy is a measure of the uncertainty of a distribution. In this sense we can say that the uncertainty contained in a distribution is the logarithm of the average probability of an event. If only one event is possible the entropy will be 0, if all events have the same probability the entropy will be maximum. The concept of entropy can be extended to continuous distributions, but we will not go into those details. <a href="#fig-entropy_bernoulli" class="quarto-xref">Figure&nbsp;<span>7.1</span></a> shows the entropy of a Bernoulli distribution for four different values of the probability of success. We can see that the entropy is maximum when the probability of success is 0.5, and minimum when the probability of success is 0.</p>
<div id="cell-fig-entropy_bernoulli" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a>_, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">2</span>, sharex<span class="op">=</span><span class="va">True</span>, sharey<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="cf">for</span> p, ax <span class="kw">in</span> <span class="bu">zip</span>([<span class="fl">0.5</span>, <span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="fl">0.0001</span>], axes.ravel()):</span>
<span id="cb1-4"><a href="#cb1-4"></a>    dist <span class="op">=</span> pz.Bernoulli(p<span class="op">=</span>p)</span>
<span id="cb1-5"><a href="#cb1-5"></a>    dist.plot_pdf(ax<span class="op">=</span>ax, legend<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb1-6"><a href="#cb1-6"></a>    ax.set_title(<span class="ss">f"Entropy=</span><span class="sc">{</span>dist<span class="sc">.</span>entropy()<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb1-7"><a href="#cb1-7"></a>    ax.set_ylim(<span class="op">-</span><span class="fl">0.05</span>, <span class="fl">1.05</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-entropy_bernoulli" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-entropy_bernoulli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Model_comparison_files/figure-html/fig-entropy_bernoulli-output-1.png" width="458" height="383" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-entropy_bernoulli-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1: Entropy of a Bernoulli distribution as a function of the probability of success
</figcaption>
</figure>
</div>
</div>
</div>
<p>The concept of entropy appears many times in statistics. It can be useful, for example when defining priors. In general we want to use a prior that has maximum entropy given our knowledge (see for example <a href="https://preliz.readthedocs.io/en/latest/">PreliZ</a>’s <a href="https://preliz.readthedocs.io/en/latest/unidimensional.html#preliz.unidimensional.maxent"><code>maxent</code></a> function). And also when comparing models as we will see in the next section.</p>
</section>
<section id="sec-kl-divergence" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="sec-kl-divergence"><span class="header-section-number">7.4.2</span> KL divergence</h3>
<p>The Kulback-Leibler divergence is a measure of how one probability distribution diverges from a second expected probability distribution. Suppose we have a target distribution <span class="math inline">\(p\)</span>, with which we cannot work directly and we only have access to a different distribution that we will call <span class="math inline">\(q\)</span>. We want to evaluate how well <span class="math inline">\(q\)</span> approximates <span class="math inline">\(p\)</span>. One way to do this is to measure the Kulback-Leibler divergence between <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>. If <span class="math inline">\(q\)</span> is a parametric family we can find the parameters making <span class="math inline">\(q\)</span> as close to <span class="math inline">\(p\)</span> as possible by minimizing the KL divergence. The KL divergence is defined as:</p>
<p><span class="math display">\[
\mathbb{KL}(p \parallel q) =  \overbrace{-\sum_i^N p_i \log{q_i}}^{H(p, q)} -  \overbrace{\left(-\sum_{i}^n p_i \log{p_i}\right)}^{H(p)}
\]</span></p>
<p>Notice that it has two components, the entropy of <span class="math inline">\(p\)</span>, <span class="math inline">\(H(p)\)</span> and the cross entropy <span class="math inline">\(H(p, q)\)</span>, that is, the entropy of <span class="math inline">\(q\)</span> but evaluated according to <span class="math inline">\(p\)</span>. This may seem somewhat abstract, but if we think that we have <span class="math inline">\(N\)</span> samples that we assume come from an unknown distribution <span class="math inline">\(p\)</span> and we have a model described by <span class="math inline">\(q(y \mid \theta)\)</span>, then we will see that we are describing a typical situation in data analysis.</p>
<p>According to this expression, the KL divergence represents the “extra” entropy that we introduce when approximating <span class="math inline">\(p\)</span> by <span class="math inline">\(q\)</span>. It is common to find it written in other ways, such as:</p>
<p><span class="math display">\[
\mathbb{KL}(p \parallel q) \quad=\quad- \sum_i^N p_i (\log{q_i} - \log{p_i}) \quad=\quad \mathbb{E}_p[\log{p}] - \mathbb{E}_p[\log{q}] \quad=\quad \sum_i^N p_i \log{\frac{p_i}{q_i}}
\]</span></p>
<p>If <span class="math inline">\(p\)</span> represents the <strong>data generating process</strong> or the <strong>population</strong> or the <strong>true</strong> distribution, and <span class="math inline">\(q\)</span> represents our model. It may seems that this expressions are all useless because we don’t know <span class="math inline">\(p\)</span>. That the reason we are trying to fit a model in the first place. But, if our goal is to compare <span class="math inline">\(m\)</span> models represented with <span class="math inline">\(q_0, q_1, \cdots, q_m\)</span>, we can can still use the KL divergence to compare them! The reason is that even when we do not know <span class="math inline">\(p\)</span>, its entropy is a constant term for all comparisons.</p>
<p><span class="math display">\[
\begin{split}
        \mathbb{KL}(p \parallel q_0) =&amp;\; \mathbb{E}[\log{p}] - \mathbb{E}[\log{q(y \mid \theta_0)}] \\
        \mathbb{KL}(p \parallel q_1) =&amp;\; \mathbb{E}[\log{p}] - \mathbb{E}[\log{q(y \mid \theta_1)}] \\
        &amp;\cdots \\
        \mathbb{KL}(p \parallel q_2) =&amp;\; \mathbb{E}[\log{p}] - \mathbb{E}[\log{q(y \mid \theta_2)}]
\end{split}
\]</span></p>
<p>This tell us that when comparing models the best model, from the set of compared models, will be the one that has the larger (log-)likelihood value. In other words, minimizing the KL divergence is proportional to maximizing likelihood.</p>
<p>This result is very general and useful, but it has a catch. In practice, we don’t really have <span class="math inline">\(\mathbb{E}[\log{q}]\)</span>, and hence we need to estimate it. We can use the observed data to estimate the parameters of a model and then use those parameters to estimate <span class="math inline">\(\mathbb{E}[\log{q}]\)</span>, but that will introduce bias. We will be overconfident about the ability of our model to explain the data. Information criteria and cross-validation provide a way to reduce this bias without having to get a new dataset.</p>
</section>
<section id="akaike-information-criterion" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="akaike-information-criterion"><span class="header-section-number">7.4.3</span> Akaike information criterion</h3>
<p>The Akaike information criterion <span class="citation" data-cites="akaike_1974">(<a href="References.html#ref-akaike_1974" role="doc-biblioref">Akaike 1974</a>)</span> (AIC) is a very well-known and widely used information criterion and is defined as:</p>
<p><span class="math display">\[
AIC = -2 \sum_i^N \log p(y_i \mid \hat{\theta}_{mle}) + 2 k
\]</span></p>
<p>Where, <span class="math inline">\(k\)</span> is the number of model parameters and <span class="math inline">\(\hat{\theta}_{mle}\)</span> is the maximum likelihood estimate for <span class="math inline">\(\theta\)</span>. For the rest of our discussion we will omit the constant -2 and write</p>
<p><span class="math display">\[
AIC = \sum_i^N \log p(y_i \mid \hat{\theta}_{mle}) - k
\]</span></p>
<p>In this way it is easier to see that the Akaike criterion is a penalized maximum likelihood, it becomes smaller the more parameters a model has. Furthermore, this version without the -2 has a clearer correspondence with other expressions which we will see below.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>That the number of parameters is a valid penalty criterion follows our intuition, a model with a greater number of parameters is, in general, more flexible. But it is interesting to note that the Akaike’s criterion has a theoretical justification, it is not that Akaike simply thought that using <span class="math inline">\(k\)</span> was a good idea.</p>
</div>
</div>
<p>The AIC criterion is very useful, but can be very limited for Bayesian models. One reason is that it uses a point estimate of <span class="math inline">\(\theta\)</span> and not the posterior distribution, hence it discards potentially useful information. Furthermore AIC, from a Bayesian perspective, assumes that priors are <em>flat</em> and therefore AIC is incompatible with informative and/or weakly informative priors. Furthermore, the number of parameters in a model is not always a good measure of its complexity. In general, a regularized model will be a model with less <em>effective number of parameters</em>. For example, when using informative priors or in hierarchical models, parameters becomes interrelated and thus the <em>effective number of parameters</em> can be smaller than the actual number of parameter. AIC has no way to account for this.</p>
<p>Can we find something like the Bayesian version of AIC? Yes, we can.</p>
</section>
<section id="elpd" class="level3" data-number="7.4.4">
<h3 data-number="7.4.4" class="anchored" data-anchor-id="elpd"><span class="header-section-number">7.4.4</span> ELPD</h3>
<p>As we already saw in the Akaike criterion, the goodness of fit is given by:</p>
<p><span class="math display">\[
\sum_i^N \log p(y_i \mid \hat{\theta}_{mle})
\]</span></p>
<p>But in Bayesian statistics, we do NOT have a point estimate of <span class="math inline">\(\theta\)</span>. We have a distribution. To account for this we could do:</p>
<p><span class="math display">\[
\sum_i^N \log \int \ p(y_i \mid \theta) \; p(\theta \mid y) d\theta
\]</span></p>
<p>In general we do not have an analytical expression for the posterior, <span class="math inline">\(p(\theta \mid y)\)</span>, instead we usually work with samples (such as those obtained by MCMC), then we can approximate the above integral by a sum over the <span class="math inline">\(S\)</span> posterior samples:</p>
<p><span class="math display">\[
\sum_i^N \log \left(\frac{1}{S} \sum _{j}^S p(y_i \mid \theta^j) \right)
\]</span></p>
<p>We will call this quantity the ELPD, which is short for expected log-predictive density. When the likelihood is discrete, we should use “probability” instead of “density”, but it is a common practice to avoid pedantry.</p>
<p>The ELPD is more Bayesian way to measure goodness of fit that the term used in AIC, but we are still missing one element, the penalization term.</p>
</section>
<section id="waic" class="level3" data-number="7.4.5">
<h3 data-number="7.4.5" class="anchored" data-anchor-id="waic"><span class="header-section-number">7.4.5</span> WAIC</h3>
<p>The Widely applicable information criterion (WAIC) uses the ELPD plus a penalization term <span class="citation" data-cites="watanabe_2013">(<a href="References.html#ref-watanabe_2013" role="doc-biblioref">Watanabe 2013</a>)</span>.</p>
<p><span class="math display">\[
WAIC = \sum_i^N \log \left(\frac{1}{S} \sum _{s}^S p(y_i \mid \theta^j) \right) - \sum_i^N \left( V_{j}^S \log p(y_i \mid \theta^j) \right)
\]</span></p>
<p>We can see that penalization term is given by the variance of the log-likelihoods over the <span class="math inline">\(S\)</span> posterior samples. Justifying this term requieres a bit more work, but the intuition is that the variance of the log-likelihoods is a measure of how much variability there is in the predictions made by the model. The more variability, the more flexible the model is. And therefore, the more we should penalize it. Let’s look at a linear model as an example:</p>
<p><span class="math display">\[
Y = \alpha + \beta X
\]</span></p>
<p>A model where <span class="math inline">\(\beta=0\)</span> will be less flexible, since it is equivalent to a model that only has one parameter, <span class="math inline">\(\alpha\)</span>. In a slightly more subtle way, a model where <span class="math inline">\(\beta\)</span> varies in a narrow range will be less flexible (more regularized), than a model where <span class="math inline">\(\beta\)</span> can take any value. WAIC properly formalized this intuition.</p>
</section>
</section>
<section id="sec-efficient-loo-cv" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="sec-efficient-loo-cv"><span class="header-section-number">7.5</span> Efficient LOO-CV</h2>
<p>We have seen that we can use information criteria to estimate the expected log-predictive density (ELPD) by introducing a penalization term to the log-likelihood, which corrects for the bias introduced when <em>double-dipping</em> our model into the data.</p>
<p>As already discussed cross-validation provides an alternative way to address this bias. The LOO-CV ELPD can be computed as:</p>
<p><span class="math display">\[
\sum_i^N  \log \left( \frac{1}{S}\sum_j^S \mathbin{\color{#E9692C}{p(y_i \mid \theta _{-i}^j)}} \right)
\]</span></p>
<p>where <span class="math inline">\(_{-i}\)</span> means that we leave observation <span class="math inline">\(i\)</span> out. A Naive implementation of this estimation requires that we estimate as many posterior distributions as observations we have, since for each of them we will eliminate one observation. However, this is not necessary since it is possible to estimate <span class="math inline">\(\color{#E9692C}{p(y_i \mid \theta _{-i}^j})\)</span> using <strong>Importance Sampling</strong>.</p>
<section id="importance-sampling" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="importance-sampling"><span class="header-section-number">7.5.1</span> Importance Sampling</h3>
<p>This is a technique for estimating properties of a distribution of interest <span class="math inline">\(f\)</span>, given that we only have samples from a distribution <span class="math inline">\(g\)</span>. Using importance sampling makes sense, for example, when it is simpler to sample <span class="math inline">\(g\)</span> than <span class="math inline">\(f\)</span>.</p>
<p>If we have a set of samples of the random variable <span class="math inline">\(X\)</span> and we can evaluate <span class="math inline">\(g\)</span> and <span class="math inline">\(f\)</span> point-wise, we can calculate the importance weights as:</p>
<p><span class="math display">\[\begin{equation}
w_i = \frac{f(x_i)}{g(x_i)}
\end{equation}\]</span></p>
<p>Computationally it looks like this:</p>
<ul>
<li>Extract <span class="math inline">\(N\)</span> samples <span class="math inline">\(x_i\)</span> from <span class="math inline">\(g\)</span></li>
<li>Calculate the probability of each sample <span class="math inline">\(g(x_i)\)</span></li>
<li>Evaluate <span class="math inline">\(f\)</span> on the <span class="math inline">\(N\)</span> samples <span class="math inline">\(f(x_i)\)</span></li>
<li>Calculate the importance weights <span class="math inline">\(w_i = \frac{f(x_i)}{g(x_i)}\)</span></li>
</ul>
<p>Once the weights <span class="math inline">\(w_i\)</span> are obtained, we can use them to estimate properties of <span class="math inline">\(f\)</span>, its density, moments, quantiles, etc.</p>
<p>In the code-block below <span class="math inline">\(g\)</span> is a Normal distribution and <span class="math inline">\(f\)</span> is a Gamma and we use importance sampling to estimate the PDF of <span class="math inline">\(f\)</span>. This is just a pedagogic example, since we actually have a very direct way to calculate the PDF of a Gamma. But in practice <span class="math inline">\(f\)</span> can be a much more complex object.</p>
<div id="ad1bd125" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>g <span class="op">=</span> pz.Normal(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a>samples <span class="op">=</span> g.rvs(<span class="dv">1000</span>, random_state<span class="op">=</span>SEED)</span>
<span id="cb2-3"><a href="#cb2-3"></a>f <span class="op">=</span> pz.Gamma(mu<span class="op">=</span><span class="dv">4</span>, sigma<span class="op">=</span><span class="fl">1.5</span>)</span>
<span id="cb2-4"><a href="#cb2-4"></a></span>
<span id="cb2-5"><a href="#cb2-5"></a>w <span class="op">=</span> f.pdf(samples) <span class="op">/</span> g.pdf(samples)</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a>ax <span class="op">=</span> f.plot_pdf()</span>
<span id="cb2-8"><a href="#cb2-8"></a>ax.hist(samples, bins<span class="op">=</span><span class="dv">100</span>, density<span class="op">=</span><span class="va">True</span>, weights<span class="op">=</span>w, </span>
<span id="cb2-9"><a href="#cb2-9"></a>        alpha<span class="op">=</span><span class="fl">0.6</span>, color<span class="op">=</span><span class="st">'C2'</span>, label<span class="op">=</span><span class="st">'Weighted samples'</span>)</span>
<span id="cb2-10"><a href="#cb2-10"></a>ax.set_xlim(<span class="dv">0</span>, <span class="dv">15</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Model_comparison_files/figure-html/cell-4-output-1.png" width="649" height="325" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>When doing importance sampling, the more similar <span class="math inline">\(g\)</span> and <span class="math inline">\(f\)</span> are, the better the results will be. In practice, inferences are more reliable when <span class="math inline">\(g\)</span> has a larger support than <span class="math inline">\(f\)</span>, that is, when it is “wider”, intuitively we need the samples of <span class="math inline">\(g\)</span> to cover the entire support of <span class="math inline">\(f\)</span>, or actually to ensure we are not missing any high-density regions.</p>
</section>
<section id="importance-sampling-and-loo-cv" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="importance-sampling-and-loo-cv"><span class="header-section-number">7.5.2</span> Importance sampling and LOO-CV</h3>
<p>The distribution we know is the posterior distribution, and the one we want to approximate by importance sampling is the posterior distribution leaving one observation out <span class="math inline">\(p(y_i \mid \theta_{-i}^j)\)</span>. Therefore, the importance weights that we are interested in calculating are:</p>
<p><span class="math display">\[
w_i^j \propto \frac{p(\theta^j \mid y_{-i} )}{p(\theta^j \mid y)} \propto \frac{p(\theta) \prod_{i\not =-i}^n p(y_i \mid \theta)}{p(\theta) \prod_i^n p(y_i \mid \theta)} \propto \frac{1}{p(y_i \mid \theta^j) }
\]</span></p>
<p>The beauty of this expression is that all terms in the numerator and the denominator will cancel out except for only one! The likelihood for the observation we want to remove, that will remain in the denominator.</p>
<p>The weights computed in this way are are not normalized, so to use them we need to divide each weight by the total sum of the weights. Once the weights have been normalized, we can use them to estimate the ELPD as:</p>
<p><span class="math display">\[
\sum_i^N \log \left( \frac{1}{S} \sum_j^S w_i^j p(y_i \mid \theta^j) \right)
\]</span></p>
<p>This result is fantastic news, it tells us that we can calculate the leave-one-out cross-validation ELPD, without having to refit the model <span class="math inline">\(N\)</span> times.</p>
<p>The catch is that the expected <span class="math inline">\(p(\theta^j \mid y_{-i})\)</span> will, in general, be wider than <span class="math inline">\(p(\theta^j \mid y)\)</span>, because it is a posterior distribution estimated with one fewer observation. This is the opposite of the ideal situation for importance sampling. Often the difference is small enough that it does not cause problems, but in some cases it can be large enough to make the approximation unreliable. When does this happen? The more influential the observation, the larger the change when we remove it.</p>
<p>Is everything lost? Not yet! In terms of importance sampling this translates into weights with greater relative importance and which therefore tend to dominate the estimation. One way to correct this problem is to simply truncate the weights that are “too high”, this can be done but is sweeping the problem under the rug. We can do something similar but better.</p>
<p>Theory indicates that, under very general conditions, the tail of the distribution of weights can be approximated by a generalized Pareto distribution. So instead of truncating them, we can fit a generalized Pareto distribution to the tail of the computed weights and then replace the original weights with draws from this fit. This is a form of <em>smoothing</em> that, within a certain range, allows stabilizing the importance sampling estimate by making some “very large” weights not so large.</p>
<p>When we combine all these ideas we get a method called Pareto-Smooth Importance Sampling Leave-One-Out Cross Validation <span class="citation" data-cites="vehtari_2017 yao_2018">(<a href="References.html#ref-vehtari_2017" role="doc-biblioref">Vehtari, Gelman, and Gabry 2017</a>; <a href="References.html#ref-yao_2018" role="doc-biblioref">Yao et al. 2018</a>)</span>, which is abbreviated as PSIS-LOO-CV.</p>
</section>
</section>
<section id="psis-loo-cv-in-arviz" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="psis-loo-cv-in-arviz"><span class="header-section-number">7.6</span> PSIS-LOO-CV in Arviz</h2>
<p>Since the name and even acronym are too long and not that easy to pronounce, in ArviZ, we usually refer to this and related methods as LOO. For example to compute the ELPD, estimated using PSIS-LOO_CV, we call the <code>loo</code> function, we just need to pass DataTree object containing a <code>log-likelihood</code> group.</p>
<div id="1ea8e93f" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>dt_rugby <span class="op">=</span> azp.load_arviz_data(<span class="st">'rugby'</span>)</span>
<span id="cb3-2"><a href="#cb3-2"></a>elpd <span class="op">=</span> azp.loo(dt_rugby, var_name<span class="op">=</span><span class="st">"home_points"</span>)</span>
<span id="cb3-3"><a href="#cb3-3"></a>elpd</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/arviz_stats/loo/helper_loo.py:1143: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>Computed from 2000 posterior samples and 60 observations log-likelihood matrix.

         Estimate       SE
elpd_loo  -282.09    26.49
p_loo       25.16        -

There has been a warning during the calculation. Please check the results.
------

Pareto k diagnostic values:
                         Count   Pct.
(-Inf, 0.70]   (good)       57   95.0%
   (0.70, 1]   (bad)         3    5.0%
    (1, Inf)   (very bad)    0    0.0%</code></pre>
</div>
</div>
<p>We can see that we get the estimated ELPD value using LOO and its standard error. <code>p_loo</code> can be roughly interpreted as the effective number of parameters. For some models this number should be close to the actual number of parameters, for models with regularization, like hierarchical models, it should be less than the actual number of parameters. After all this introduction, actually computing LOO may seem somewhat disappointing.</p>
<p>To compare two or more models, we can use the <code>compare</code> function, which accepts a dictionary where the keys are the names of the models and the values are <code>DataTree</code> objects.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="ppl">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" href="" aria-current="page">PyMC</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false" href="">CmdStanPy</a></li></ul>
<div class="tab-content" data-group="ppl">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div id="783b3a3b" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>target <span class="op">=</span> pz.StudentT(nu<span class="op">=</span><span class="dv">4</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>).rvs(<span class="dv">200</span>, random_state<span class="op">=</span>SEED)</span>
<span id="cb6-2"><a href="#cb6-2"></a></span>
<span id="cb6-3"><a href="#cb6-3"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_n:</span>
<span id="cb6-4"><a href="#cb6-4"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">"μ"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-5"><a href="#cb6-5"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">"σ"</span>, <span class="dv">1</span>)</span>
<span id="cb6-6"><a href="#cb6-6"></a>    pm.Normal(<span class="st">"y"</span>, μ, σ, observed<span class="op">=</span>target)</span>
<span id="cb6-7"><a href="#cb6-7"></a>    idata_n <span class="op">=</span> pm.sample(idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>:<span class="va">True</span>})</span>
<span id="cb6-8"><a href="#cb6-8"></a>    </span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_t:</span>
<span id="cb6-10"><a href="#cb6-10"></a>    μ <span class="op">=</span> pm.Normal(<span class="st">"μ"</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-11"><a href="#cb6-11"></a>    σ <span class="op">=</span> pm.HalfNormal(<span class="st">"σ"</span>, <span class="dv">1</span>)</span>
<span id="cb6-12"><a href="#cb6-12"></a>    ν <span class="op">=</span> pm.Exponential(<span class="st">"ν"</span>, scale<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb6-13"><a href="#cb6-13"></a>    pm.StudentT(<span class="st">"y"</span>, nu<span class="op">=</span>ν, mu<span class="op">=</span>μ, sigma<span class="op">=</span>σ, observed<span class="op">=</span>target)</span>
<span id="cb6-14"><a href="#cb6-14"></a>    idata_t <span class="op">=</span> pm.sample(idata_kwargs<span class="op">=</span>{<span class="st">"log_likelihood"</span>:<span class="va">True</span>})</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co">## coming soon</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div id="1f17520f" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>cmp_df <span class="op">=</span> azp.compare({<span class="st">'model_n'</span>:idata_n, <span class="st">'model_t'</span>:idata_t})</span>
<span id="cb8-2"><a href="#cb8-2"></a>cmp_df</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">rank</th>
<th data-quarto-table-cell-role="th">elpd</th>
<th data-quarto-table-cell-role="th">p</th>
<th data-quarto-table-cell-role="th">elpd_diff</th>
<th data-quarto-table-cell-role="th">weight</th>
<th data-quarto-table-cell-role="th">se</th>
<th data-quarto-table-cell-role="th">dse</th>
<th data-quarto-table-cell-role="th">warning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">model_t</th>
<td>0</td>
<td>-327.519119</td>
<td>3.406163</td>
<td>0.000000</td>
<td>1.0</td>
<td>13.470384</td>
<td>0.000000</td>
<td>False</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">model_n</th>
<td>1</td>
<td>-334.187731</td>
<td>3.187292</td>
<td>6.668612</td>
<td>0.0</td>
<td>15.124893</td>
<td>4.510585</td>
<td>False</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>In the rows we have the compared models and in the columns we have</p>
<ul>
<li>rank: the order of the models (from best to worst)</li>
<li>elpd_loo: the point estimate of the ELPD using LOO</li>
<li>p_loo: the effective number of parameters</li>
<li>elpd_diff: the difference between the ELPD of the best model and the other models</li>
<li>weight: the relative weight of each model. If we wanted to make predictions by combining the different models, instead of choosing just one, this would be the weight we should assign to each model. In this case we see that <code>model_t</code> takes all the weight.</li>
<li>se: the standard error of the ELPD</li>
<li>dse: the standard error of the differences</li>
<li>warning: a warning about whether there is at least one high k value</li>
<li>scale: the scale on which the ELPD is calculated</li>
</ul>
<p>We can obtain similar information, but graphically, using the <code>azp.plot_compare</code> function</p>
<div id="272ef09a" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a>azp.plot_compare(cmp_df)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Model_comparison_files/figure-html/cell-9-output-1.png" width="908" height="209" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>The open circles represent the ELPD values ​​and black lines the standard error.</li>
<li>The highest ELPD value is indicated with a vertical dashed gray line for easy comparison with other values.</li>
<li>For all models except <em>the best</em>, we also obtain a triangle indicating the value of the ELPD difference between each model and the <em>best</em> model. The gray error bar indicating the standard error of the differences between the point estimates.</li>
</ul>
<p>The simplest way to use information criteria is to choose a single model. Simply choose the model with the highest ELPD value. If we follow this rule we will have to accept that the quadratic model is the best. Even if we take into account the standard errors we can see that they do not overlap. Which gives us some security that the models are indeed <em>different</em> from each other. If, instead, the standard errors overlapped, we should provide a more nuanced answer.</p>
<section id="pareto-k-and-loo-diagnostics" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="pareto-k-and-loo-diagnostics"><span class="header-section-number">7.6.1</span> Pareto k and LOO diagnostics</h3>
<p>Then we see a table titled “Pareto k diagnostic values”. Earlier we said that we use a method involving a Pareto distribution to regularize the estimation of the importance weights. One of the parameters of that fit is called <span class="math inline">\(k\)</span>, and its estimate is often written as <span class="math inline">\(\hat{k}\)</span>. Because we compute a Pareto adjustment per observation, we obtain one <span class="math inline">\(\hat{k}\)</span> value per observation. This parameter is useful because it tells us two related things: when an observation is “very influential” and when the LOO approximation may be failing for that observation.</p>
<p>As a general rule, if <span class="math inline">\(\hat{k}\)</span> is less than 0.7 there are no problems; if it is between 0.7 and 1 it is very likely that we are in trouble; and if it is greater than 1, we are doomed. The cut-off value 0.7 is not fixed, it can in principle be lower, and it depends on the total number of posterior draws (2000 in this example). But when the number of draws is about 2000, the recommended threshold is close to 0.7. In practice, it is common to use at least 2000 posterior draws. Increasing the number of samples from the posterior may reduce the value of <span class="math inline">\(\hat{k}\)</span> and thus remove some of these warnings, but in general the number needed will be too large to be practically useful.</p>
<p>It is possible to visualize the values ​​of <span class="math inline">\(k\)</span>, using <code>plot_khat</code></p>
<div id="3965c4d9" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co"># coming soon</span></span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="co">#azp.plot_khat(elpd, threshold=0.7);</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>While the main function of LOO is to compare models, the values ​​of <span class="math inline">\(k\)</span> can be useful even if we only have only one model. For example, we could have extra knowledge that tells us why these observations are influential, perhaps there was a problem in data collection and the values ​​are incorrect. Or perhaps the values ​​are correct but from the perspective of our model they are influential, “strange”, “surprising”.</p>
<p>If <span class="math inline">\(k &gt; 0.7\)</span>, the value of <code>p_loo</code> can give us some more information, where <span class="math inline">\(p\)</span> is the total number of parameters in a model.</p>
<ul>
<li><p>If <span class="math inline">\(p_{\text{loo}} &lt;&lt; p\)</span> then the model must be misspecified. This should also be seen in post-hoc predictive testing. One solution is to use an overdispersed model (such as changing a Poisson for a NegativeBinomial or for a ZeroInflatedPoisson or HurdlePoisson, or changing a Normal for a Student’s T, etc.). Or it is likely that the model needs more structure or complexity, perhaps we need a non-linear term, etc.</p></li>
<li><p>If <span class="math inline">\(p_{\text{loo}} &lt; p\)</span> and the observations are relatively few compared to <span class="math inline">\(p\)</span>, (say <span class="math inline">\(p&gt;N/5\)</span>). It is likely that we have a model that is too flexible and/or priors that are too vague. This can happen for hierarchical models with very few observations per group or for example for splines with many knots or Gaussian processes with very short scale values.</p></li>
<li><p>If <span class="math inline">\(p_{\text{loo}} &gt; p\)</span>, then the model has very serious problems. If <span class="math inline">\(p&lt;&lt;N\)</span>, then posterior predictive tests should also report problems. If, however, p is relatively large (say <span class="math inline">\(p&gt;N/5\)</span>). So post-hoc predictive testing may not reflect problems.</p></li>
</ul>
</section>
</section>
<section id="sec-IWMM-theory" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="sec-IWMM-theory"><span class="header-section-number">7.7</span> When Pareto k values are too high</h2>
<p>The efficiency of PSIS-LOO-CV depends critically on stable importance sampling, which breaks down when the Pareto-<span class="math inline">\(k\)</span> diagnostic exceeds a threshold (typically around 0.7 for standard MCMC sample sizes), leading to unreliable estimates.</p>
<p>When observations produce high Pareto-<span class="math inline">\(k\)</span> values, we can use standard LOO-CV for those observations, i.e.&nbsp;refit the model while removing those problematic observations one at a time. This could be useful if the number of observations with high <span class="math inline">\(\hat k\)</span> is small, otherwise it can easily become too expensive for routine use. K-fold CV is another option but it can also be too expensive.</p>
<p>But those are not the only two solutions when PSIS-LOO-CV produces high <span class="math inline">\(\hat k\)</span> values. Instead of expensive model refitting, the method <strong>importance weighted moment matching (IWMM)</strong>, presented by <span class="citation" data-cites="paananen_2020">Paananen et al. (<a href="References.html#ref-paananen_2020" role="doc-biblioref">2020</a>)</span>, works by improving the proposal distribution by iteratively transforming existing posterior draws to better match the moments of the target distribution.</p>
<p>To understand how moment matching improves these importance weights, we first need to understand which Monte Carlo estimator we are using.</p>
<section id="monte-carlo-estimators" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="monte-carlo-estimators"><span class="header-section-number">7.7.1</span> Monte Carlo estimators</h3>
<p>Two of the most commonly used estimators are standard importance sampling (IS) and self-normalized importance sampling (SNIS). The choice between IS and SNIS determines which proposal distribution works best, which in turn affects how moment matching should adapt the draws.</p>
<p>The central problem we’re interested in is computing <span class="math inline">\(\mathbb{E}_p[h(\theta)] = \int h(\theta) p(\theta) \, d\theta\)</span> using draws <span class="math inline">\(\{\theta^{(s)}\}_{s=1}^S\)</span> from a proposal distribution <span class="math inline">\(g(\theta)\)</span>.</p>
<section id="standard-importance-sampling-is" class="level4" data-number="7.7.1.1">
<h4 data-number="7.7.1.1" class="anchored" data-anchor-id="standard-importance-sampling-is"><span class="header-section-number">7.7.1.1</span> Standard Importance Sampling (IS)</h4>
<p>The standard importance sampling estimator computes the expectation as <span class="math display">\[
\hat{\mu}_{\text{IS}} = \frac{1}{S} \sum_{s=1}^S w^{(s)} h(\theta^{(s)}), \quad w^{(s)} = \frac{p(\theta^{(s)})}{g(\theta^{(s)})},
\]</span></p>
<p>which is unbiased when normalizing constants are known, with variance depending on how well <span class="math inline">\(g(\theta)\)</span> matches the target in regions where <span class="math inline">\(|h(\theta)|\)</span> is large.</p>
</section>
<section id="self-normalized-importance-sampling-snis" class="level4" data-number="7.7.1.2">
<h4 data-number="7.7.1.2" class="anchored" data-anchor-id="self-normalized-importance-sampling-snis"><span class="header-section-number">7.7.1.2</span> Self-Normalized Importance Sampling (SNIS)</h4>
<p>The SNIS estimator computes the ratio of weighted averages as <span class="math display">\[
\hat{\mu}_{\text{SNIS}} = \frac{\sum_{s=1}^S w^{(s)} h(\theta^{(s)})}{\sum_{s=1}^S w^{(s)}}, \quad w^{(s)} = \frac{p(\theta^{(s)})}{g(\theta^{(s)})}.
\]</span></p>
<p>This is a natural choice for PSIS-LOO-CV because the normalizing constants of <span class="math inline">\(p(\theta \mid y_{-i})\)</span> and <span class="math inline">\(p(\theta \mid y)\)</span> are typically unknown.</p>
<p>SNIS introduces an additional consideration. We need to estimate both numerator and denominator accurately, which changes which regions of the proposal matter most. The optimal proposal for SNIS emphasizes where <span class="math inline">\(|h(\theta) - \mathbb{E}_p[h(\theta)]|\)</span> is large, whereas for standard IS it emphasizes where <span class="math inline">\(|h(\theta)|\)</span> is large. In practice, we use self-normalized weights <span class="math inline">\(\tilde{w}^{(s)} = w^{(s)} / \sum_{r=1}^S w^{(r)}\)</span> for moment matching since normalizing constants are often unknown.</p>
</section>
</section>
<section id="multiple-importance-sampling" class="level3" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="multiple-importance-sampling"><span class="header-section-number">7.7.2</span> Multiple importance sampling</h3>
<p>The distinction between numerator and denominator adaptation for SNIS creates a challenge. As we will see later, the optimal proposal for the numerator differs from the optimal proposal for the denominator. Rather than choosing between these competing proposals, moment matching uses multiple importance sampling to combine them. MIS provides a principled framework for sampling from <span class="math inline">\(J\)</span> different proposal distributions and combining the results into a single estimator with provably good properties.</p>
<p>Suppose we independently draw <span class="math inline">\(S_j\)</span> samples from each of <span class="math inline">\(J\)</span> proposal distributions <span class="math inline">\(g_1(\theta), \ldots, g_J(\theta)\)</span>, with <span class="math inline">\(\sum_{j=1}^J S_j = S\)</span> total draws. The multiple importance sampling estimator is</p>
<p><span class="math display">\[\hat{\mu}_{\mathrm{MIS}} = \sum_{j=1}^{J} \frac{1}{S_j} \sum_{s=1}^{S_j} \beta_j(\theta^{(j,s)}) \frac{p(\theta^{(j,s)})}{g_j(\theta^{(j,s)})} h(\theta^{(j,s)}),\]</span></p>
<p>where <span class="math inline">\(\{\beta_j(\theta)\}_{j=1}^{J}\)</span> forms a partition of unity with <span class="math inline">\(\beta_j(\theta) \geq 0\)</span> and <span class="math inline">\(\sum_{j=1}^J \beta_j(\theta) = 1\)</span> for all <span class="math inline">\(\theta\)</span>. The weighting functions <span class="math inline">\(\beta_j\)</span> determine how much each proposal contributes at different points in the parameter space.</p>
<p>A natural choice for the weighting functions is the <em>balance heuristic</em></p>
<p><span class="math display">\[\beta_j(\theta) = \frac{S_j g_j(\theta)}{\sum_{k=1}^J S_k g_k(\theta)}.\]</span></p>
<p>A critical property of this weighting function is that it can be shown that the variance of the MIS estimator using the balance heuristic is provably smaller than the variance of any single proposal distribution, plus a term that vanishes as the sample sizes grow.</p>
<p>Intuitively, the balance heuristic computes importance weights as if all draws came from a mixture proposal <span class="math inline">\(g_{\alpha}(\theta) = \sum_{j=1}^J \alpha_j g_j(\theta)\)</span> where <span class="math inline">\(\alpha_j = S_j / S\)</span>, which gives us the weights</p>
<p><span class="math display">\[w^{(j,s)} = \frac{p(\theta^{(j,s)})}{g_{\alpha}(\theta^{(j,s)})} = \frac{p(\theta^{(j,s)})}{\sum_{j=1}^J \alpha_j g_j(\theta^{(j,s)})}.\]</span></p>
<p>This framework becomes crucial for moment matching when adapting two separate proposal distributions, because rather than choosing between them, we can combine both using MIS and the balance heuristic.</p>
</section>
<section id="importance-weighted-moment-matching" class="level3" data-number="7.7.3">
<h3 data-number="7.7.3" class="anchored" data-anchor-id="importance-weighted-moment-matching"><span class="header-section-number">7.7.3</span> Importance weighted moment matching</h3>
<p>Moment matching extends the idea of PSIS-LOO-CV in a clever way. It <em>implicitly</em> updates the proposal without needing auxiliary parameters or resampling. Traditional adaptive importance sampling alternates between drawing samples, computing weights, and updating parameters. The key insight from <span class="citation" data-cites="paananen_2020">Paananen et al. (<a href="References.html#ref-paananen_2020" role="doc-biblioref">2020</a>)</span> is simpler: skip generating fresh draws and instead repeatedly transform the existing draws from <span class="math inline">\(p(\theta \mid y)\)</span> in the unconstrained parameter space. These transformations align the low-order moments of the draws with the moments implied by the leave-one-out weights.</p>
<p>This implicit adaptation is fully automated and requires only operations on already available posterior draws. It’s designed to plug into PSIS-LOO-CV pipelines that flag problematic cases using the Pareto-<span class="math inline">\(k\)</span> diagnostic from <span class="citation" data-cites="vehtari_2017">Vehtari, Gelman, and Gabry (<a href="References.html#ref-vehtari_2017" role="doc-biblioref">2017</a>)</span>. Because we reuse the same Monte Carlo sample throughout, the computational cost stays close to that of a single PSIS-LOO-CV evaluation, even when several adaptation rounds are attempted. Importantly, this approach preserves the effective sample size accrued during the original posterior simulation and avoids delicate tuning choices.</p>
<p>The approach involves several key components:</p>
<ul>
<li>Apply affine transformations to existing draws to better match the target distribution</li>
<li>Recognize that different Monte Carlo estimators require different proposal strategies</li>
<li>Identify optimal proposal distributions for both standard and self-normalized importance sampling</li>
<li>Approximate the challenging self-normalized optimal proposal using a split proposal that separates numerator and denominator adaptation</li>
<li>Combine the adapted proposals using multiple importance sampling</li>
</ul>
<p>The following sections develop each of these ideas in turn.</p>
<section id="affine-transformations-and-implicit-adaptation" class="level4" data-number="7.7.3.1">
<h4 data-number="7.7.3.1" class="anchored" data-anchor-id="affine-transformations-and-implicit-adaptation"><span class="header-section-number">7.7.3.1</span> Affine transformations and implicit adaptation</h4>
<p>The core idea of importance weighted moment matching (IWMM) is to transform existing draws to better match the target distribution without resampling. We achieve this using affine transformations guided by importance-weighted moments.</p>
<p>Consider a set of draws <span class="math inline">\(\{\theta^{(s)}\}_{s=1}^S\)</span> from the full-data posterior <span class="math inline">\(p(\theta \mid y)\)</span>. A generic affine transformation consists of a square matrix <span class="math inline">\(\mathbf{A}\)</span> and a translation vector <span class="math inline">\(\mathbf{b}\)</span> such that</p>
<p><span class="math display">\[
T(\theta^{(s)}) = \mathbf{A}\theta^{(s)} + \mathbf{b} = \theta^{*(s)}.
\]</span></p>
<p>Since the transformations are affine and the same for all draws, the implicit density of the transformed draws is</p>
<p><span class="math display">\[
g_T(\theta^{*(s)}) = p(\theta^{(s)} \mid y) |\mathbf{J}_T|^{-1},
\]</span></p>
<p>where <span class="math inline">\(|\mathbf{J}_T|^{-1} = |\det(\mathbf{A})|^{-1}\)</span> is the inverse Jacobian determinant. Crucially, this allows us to evaluate the proposal density at the transformed draws without ever writing down an explicit functional form. The proposal is adapted <em>implicitly</em> through the transformation, which requires an invertible matrix <span class="math inline">\(\mathbf{A}\)</span> so that the Jacobian determinant is well defined.</p>
<p>When moment matching is applied to leave-one-out cross-validation, the importance weights must be recomputed after each transformation. For a transformed draw <span class="math inline">\(\theta^{*(s)}\)</span>, the importance weight becomes</p>
<p><span class="math display">\[
w_{\text{loo}, i}^{*(s)} = \frac{p(\theta^{*(s)} \mid y)}{p(\theta^{(s)} \mid y) \, p(y_i \mid \theta^{*(s)})} \propto \frac{p(\theta^{*(s)} \mid y_{-i})}{p(\theta^{(s)} \mid y)},
\]</span></p>
<p>which is still proportional to the ratio of the LOO posterior to the original proposal. This reweighting accounts for both the density of the transformed draw under the full-data posterior and its likelihood for observation <span class="math inline">\(i\)</span>. The denominator term <span class="math inline">\(p(\theta^{(s)} \mid y)\)</span> remains constant for each draw across all LOO folds, but the numerator terms must be evaluated at each transformed location.</p>
</section>
<section id="targeting-optimal-proposal-distributions" class="level4" data-number="7.7.3.2">
<h4 data-number="7.7.3.2" class="anchored" data-anchor-id="targeting-optimal-proposal-distributions"><span class="header-section-number">7.7.3.2</span> Targeting optimal proposal distributions</h4>
<p>The affine transformations need some target to guide them. The choice of target determines whether moment matching successfully reduces the Pareto-<span class="math inline">\(k\)</span> diagnostic. The theoretically optimal proposal density depends on both the function <span class="math inline">\(h(\theta)\)</span> being estimated and the weighting scheme used.</p>
<p>For standard importance sampling, the optimal proposal is</p>
<p><span class="math display">\[
g_{\mathrm{IS}}^{\mathrm{opt}}(\theta) \propto p(\theta)\lvert h(\theta)\rvert,
\]</span></p>
<p>which emphasizes regions where <span class="math inline">\(|h(\theta)|\)</span> is large. For self-normalized importance sampling, the optimal proposal is</p>
<p><span class="math display">\[
g_{\mathrm{SNIS}}^{\mathrm{opt}}(\theta) \propto p(\theta)\left|h(\theta)-\mathbb{E}_{p}[h(\theta)]\right|,
\]</span></p>
<p>which emphasizes regions where <span class="math inline">\(h(\theta)\)</span> deviates from its expectation.</p>
<p>The difference arises because SNIS must estimate both numerator and denominator accurately. When <span class="math inline">\(h(\theta)\)</span> varies substantially, we need draws where <span class="math inline">\(h(\theta)\)</span> deviates most from its mean. When <span class="math inline">\(h(\theta)\)</span> is roughly constant, we need draws emphasizing posterior mass. Moment matching uses the available importance weights to steer affine transformations toward these optimal shapes.</p>
<p>To make this work in practice, we use two types of weights:</p>
<ul>
<li><strong>Common weights</strong> <span class="math inline">\(w^{(s)} = p(\theta^{(s)}) / g(\theta^{(s)})\)</span> quantify the mismatch between proposal and target independent of the function <span class="math inline">\(h\)</span></li>
<li><strong>Expectation-specific weights</strong> <span class="math inline">\(v^{(s)} = h(\theta^{(s)}) w^{(s)}\)</span> weight each draw by both the density ratio and the integrand value</li>
</ul>
<p>The transformations are calibrated with <span class="math inline">\(\{w^{(s)}\}\)</span> or with <span class="math inline">\(\{|v^{(s)}|\}\)</span>, depending on whether the denominator or numerator of the SNIS estimator needs improvement. We use absolute values <span class="math inline">\(|v^{(s)}|\)</span> because both positive and negative values of <span class="math inline">\(h(\theta)\)</span> contribute equally to variance, so we want draws where the magnitude is large regardless of sign.</p>
</section>
<section id="the-split-proposal-for-snis" class="level4" data-number="7.7.3.3">
<h4 data-number="7.7.3.3" class="anchored" data-anchor-id="the-split-proposal-for-snis"><span class="header-section-number">7.7.3.3</span> The split proposal for SNIS</h4>
<p>The SNIS optimal proposal from the previous section presents a practical challenge. It can easily be multimodal even when the expectation is defined over a unimodal distribution, making it difficult to approximate with simple affine transformations. It also depends on the unknown expectation <span class="math inline">\(\mathbb{E}_p[h(\theta)]\)</span>.</p>
</section>
<section id="the-split-proposal-approximation" class="level4" data-number="7.7.3.4">
<h4 data-number="7.7.3.4" class="anchored" data-anchor-id="the-split-proposal-approximation"><span class="header-section-number">7.7.3.4</span> The split proposal approximation</h4>
<p>To combine the two adaptation strategies into an efficient proposal distribution, <span class="citation" data-cites="paananen_2020">Paananen et al. (<a href="References.html#ref-paananen_2020" role="doc-biblioref">2020</a>)</span> develop a practical approximation called the <em>split proposal density</em> given by</p>
<p><span class="math display">\[
g_{\mathrm{SNIS}}^{\mathrm{split}}(\theta) \propto |h(\theta)|p(\theta) + \mathbb{E}_{p}[h(\theta)]p(\theta).
\]</span></p>
<p>This approximation splits the piecewise-defined optimal proposal into two clear components. The first component <span class="math inline">\(|h(\theta)|p(\theta)\)</span> is proportional to the optimal proposal for standard importance sampling and uses the absolute expectation-specific weights <span class="math inline">\(\{|v^{(s)}|\}\)</span>. The second component <span class="math inline">\(\mathbb{E}_{p}[h(\theta)]p(\theta)\)</span> is proportional to the target distribution <span class="math inline">\(p(\theta)\)</span> itself and uses the common weights <span class="math inline">\(\{w^{(s)}\}\)</span>. This split form is a convenient approximation that has similar tail behavior to the SNIS optimal proposal while being simpler to work with. It avoids the potentially complex multimodal structure of <span class="math inline">\(|h(\theta) - \mathbb{E}_p[h(\theta)]|\)</span> by separating it into two interpretable components.</p>
<p>The trade-off is that this approximation places unnecessary probability mass in regions where <span class="math inline">\(h(\theta) \approx \mathbb{E}_p[h(\theta)]\)</span>, thus losing some efficiency. However, the approximation works best precisely when we need it most. When <span class="math inline">\(p(\theta)\)</span> is more distinct from <span class="math inline">\(p(\theta)|h(\theta)|\)</span>, the value of <span class="math inline">\(\mathbb{E}_p[h(\theta)]\)</span> becomes smaller and the approximation becomes closer to the optimal form. These are exactly the cases when adaptive importance sampling is most beneficial.</p>
</section>
<section id="double-adaptation-strategy" class="level4" data-number="7.7.3.5">
<h4 data-number="7.7.3.5" class="anchored" data-anchor-id="double-adaptation-strategy"><span class="header-section-number">7.7.3.5</span> Double adaptation strategy</h4>
<p>The split proposal naturally suggests a double adaptation strategy. We run two separate moment matching procedures in parallel: one uses the absolute expectation-specific weights <span class="math inline">\(\{|v^{(s)}|\}\)</span> to approximate the first component, and the other uses the common weights <span class="math inline">\(\{w^{(s)}\}\)</span> to approximate the second. These two adapted proposal distributions are then combined using multiple importance sampling with the balance heuristic.</p>
<p>When <span class="math inline">\(h(\theta) \geq 0\)</span>, both components integrate to <span class="math inline">\(\mathbb{E}_p[h(\theta)]\)</span>. <span class="citation" data-cites="paananen_2020">Paananen et al. (<a href="References.html#ref-paananen_2020" role="doc-biblioref">2020</a>)</span> show that equal allocation (50-50 split) is provably optimal in this case and more generally is a conservative choice that guarantees the asymptotic variance is never more than twice that of using the better component alone.</p>
</section>
<section id="three-moment-matching-transformations" class="level4" data-number="7.7.3.6">
<h4 data-number="7.7.3.6" class="anchored" data-anchor-id="three-moment-matching-transformations"><span class="header-section-number">7.7.3.6</span> Three moment matching transformations</h4>
<p>Our overall goal is to transform the existing posterior draws to match the optimal proposals. To do this, we match progressively more moments of the distribution to importance-weighted moments.</p>
<p><span class="citation" data-cites="paananen_2020">Paananen et al. (<a href="References.html#ref-paananen_2020" role="doc-biblioref">2020</a>)</span> recommend a sequence of three affine transformations with increasing complexity. The transformations use importance weights to identify where the target distribution places its mass relative to the proposal. We start with the simplest transformation and progress to more complex ones only when simpler ones no longer improve the Pareto-<span class="math inline">\(k\)</span> diagnostic.</p>
<p><strong>Transformation <span class="math inline">\(T_1\)</span> (matching the mean).</strong> The simplest transformation shifts the sample mean to match the importance-weighted mean</p>
<p><span class="math display">\[
\theta^{*(s)} = T_1(\theta^{(s)}) = \theta^{(s)} - \bar{\theta} + \bar{\theta}_w,
\]</span></p>
<p>where the unweighted mean is <span class="math inline">\(\bar{\theta} = \frac{1}{S} \sum_{s=1}^S \theta^{(s)}\)</span> and the self-normalized importance-weighted mean is</p>
<p><span class="math display">\[
\bar{\theta}_w = \frac{\sum_{s=1}^S w^{(s)} \theta^{(s)}}{\sum_{s=1}^S w^{(s)}} = \sum_{s=1}^S \tilde{w}^{(s)} \theta^{(s)},
\]</span></p>
<p>with <span class="math inline">\(\tilde{w}^{(s)} = w^{(s)} / \sum_{r=1}^S w^{(r)}\)</span> denoting the self-normalized weights.</p>
<p><strong>Transformation <span class="math inline">\(T_2\)</span> (matching marginal variances).</strong> The second transformation matches both the mean and the marginal variances</p>
<p><span class="math display">\[
\theta^{*(s)} = T_2(\theta^{(s)}) = \mathbf{v}_w^{1/2} \circ \mathbf{v}^{-1/2} \circ (\theta^{(s)} - \bar{\theta}) + \bar{\theta}_w,
\]</span></p>
<p>where <span class="math inline">\(\circ\)</span> denotes element-wise multiplication, <span class="math inline">\(\mathbf{v}\)</span> is the vector of unweighted marginal variances, and <span class="math inline">\(\mathbf{v}_w\)</span> is the vector of importance-weighted marginal variances computed as</p>
<p><span class="math display">\[
\mathbf{v}_w = \sum_{s=1}^S \tilde{w}^{(s)} (\theta^{(s)} - \bar{\theta}_w) \circ (\theta^{(s)} - \bar{\theta}_w) = \frac{\sum_{s=1}^S w^{(s)} (\theta^{(s)} - \bar{\theta}_w) \circ (\theta^{(s)} - \bar{\theta}_w)}{\sum_{s=1}^S w^{(s)}}.
\]</span></p>
<p><strong>Transformation <span class="math inline">\(T_3\)</span> (matching the covariance).</strong> The most sophisticated transformation matches the full covariance structure</p>
<p><span class="math display">\[
\theta^{*(s)} = T_3(\theta^{(s)}) = \mathbf{L}_w \mathbf{L}^{-1} (\theta^{(s)} - \bar{\theta}) + \bar{\theta}_w,
\]</span></p>
<p>where <span class="math inline">\(\mathbf{L}\mathbf{L}^\top = \boldsymbol{\Sigma}\)</span> and <span class="math inline">\(\mathbf{L}_w\mathbf{L}_w^\top = \boldsymbol{\Sigma}_w\)</span> are Cholesky decompositions of the sample and weighted covariance matrices, with the weighted covariance computed as</p>
<p><span class="math display">\[
\boldsymbol{\Sigma}_w = \sum_{s=1}^S \tilde{w}^{(s)} (\theta^{(s)} - \bar{\theta}_w)(\theta^{(s)} - \bar{\theta}_w)^\top = \frac{\sum_{s=1}^S w^{(s)} (\theta^{(s)} - \bar{\theta}_w)(\theta^{(s)} - \bar{\theta}_w)^\top}{\sum_{s=1}^S w^{(s)}}.
\]</span></p>
</section>
<section id="the-moment-matching-algorithm" class="level4" data-number="7.7.3.7">
<h4 data-number="7.7.3.7" class="anchored" data-anchor-id="the-moment-matching-algorithm"><span class="header-section-number">7.7.3.7</span> The moment matching algorithm</h4>
<p>The ArviZ implementation uses a greedy search strategy for each observation with high Pareto-<span class="math inline">\(k\)</span> values. For each problematic observation, the algorithm iteratively tries the three transformations in sequence. When the mean shift transformation (<span class="math inline">\(T_1\)</span>) reduces the Pareto-<span class="math inline">\(k\)</span> diagnostic, it is accepted and the algorithm restarts from <span class="math inline">\(T_1\)</span> again. Only when <span class="math inline">\(T_1\)</span> fails to improve the diagnostic does the algorithm try the variance transformation (<span class="math inline">\(T_2\)</span>), and similarly for the covariance transformation (<span class="math inline">\(T_3\)</span>) when enabled. This process continues until no transformation improves the diagnostic or the maximum number of iterations is reached.</p>
<p>After the transformations converge, ArviZ applies an optional split proposal strategy by default. The cumulative transformation is applied to the first half of the posterior draws while the inverse transformation is applied to the second half. These two sets of transformed draws are then combined using multiple importance sampling with the balance heuristic. This split approach helps avoid potential bias from reusing the same draws and often improves the stability of the final estimates. The entire workflow is automated through the <code>loo_moment_match()</code> function.</p>
</section>
</section>
</section>
<section id="sec-subsampledloo-theory" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="sec-subsampledloo-theory"><span class="header-section-number">7.8</span> When the dataset is too large</h2>
<p>Comparing Bayesian models on large datasets presents a computational challenge. Full leave-one-out cross-validation (LOO) requires computing <span class="math inline">\(n\)</span> posteriors and brute force K-fold cross-validation methods become prohibitively expensive as data size grows.</p>
<p>To overcome these challenges, we will use the approach described in <span class="citation" data-cites="magnusson_2020">Magnusson et al. (<a href="References.html#ref-magnusson_2020" role="doc-biblioref">2020</a>)</span> to combine fast approximations with targeted, exact computations. The key idea is to use cheap approximations, called <em>surrogates</em>, for all <span class="math inline">\(n\)</span> observations, and then correct these approximations using exact Pareto smoothed importance sampling (PSIS) LOO-CV on just a small random subsample with a <em>difference estimator</em> that corrects for the approximation error across the full dataset.</p>
<section id="from-loo-to-subsampled-loo" class="level3" data-number="7.8.1">
<h3 data-number="7.8.1" class="anchored" data-anchor-id="from-loo-to-subsampled-loo"><span class="header-section-number">7.8.1</span> From LOO to subsampled LOO</h3>
<p>As mentioned earlier in this chapter, PSIS-LOO-CV uses importance sampling to approximate LOO-CV without refitting the model <span class="math inline">\(n\)</span> times. The Pareto-<span class="math inline">\(k\)</span> diagnostic flags unreliable importance sampling approximations when <span class="math inline">\(k &gt; 0.7\)</span>. For large <span class="math inline">\(n\)</span>, even this efficient computation becomes expensive.</p>
<p>The key insight for large data is to combine three elements:</p>
<ol type="1">
<li><strong>Fast surrogates</strong> <span class="math inline">\(\tilde\pi_i\)</span> computed for all <span class="math inline">\(n\)</span> observations (e.g., point predictions)</li>
<li><strong>Exact PSIS-LOO-CV</strong> computed only on a small random subsample <span class="math inline">\(\mathcal{S}\)</span> of size <span class="math inline">\(m \ll n\)</span></li>
<li><strong>The difference estimator</strong> to correct the surrogates using the subsample</li>
</ol>
<p>These elements dramatically reduce computational cost while maintaining statistical accuracy. We can also extend the importance ratios with the correction term <span class="math inline">\(p(\theta_s \mid y)/q(\theta_s \mid y)\)</span> when using approximate posteriors from variational inference or Laplace approximations to further reduce computational cost.</p>
<p>A surrogate is simply a computationally inexpensive approximation of each observation’s LOO predictive density, such as evaluating the likelihood at the posterior mean, that doesn’t require refitting the model. The difference estimator then uses the subsample to correct for approximation errors across the full dataset. The result is accurate estimates of predictive performance with a fraction of the computational cost, making model comparison feasible even when <span class="math inline">\(n\)</span> is very large.</p>
<p>A critical component of the difference estimator is using simple random sampling to select the subsample, rather than model-specific importance sampling schemes. This allows the auxiliary information, e.g., the surrogates <span class="math inline">\(\tilde\pi_i\)</span>, to be used in the estimation stage rather than the sampling stage, meaning the same subsample can be efficiently reused for all models and all quantities of interest. Alternative approaches that incorporate model-specific information during sampling, such as the <strong>Hansen-Hurwitz</strong> estimator, which we will describe later, require drawing separate subsamples for each model and each comparison, multiplying computational costs.</p>
<p>The quality of surrogate approximations <span class="math inline">\(\tilde\pi_i\)</span> plays a key role in determining the required subsample size. Surrogates that incorporate model complexity through the effective number of parameters <span class="math inline">\(p_{\text{eff}} = V_\theta(\log p(y_i \mid \theta))\)</span> tend to approximate the true LOO contributions better than simple point predictions, especially for hierarchical or weakly identified models. This improvement can reduce the required subsample size by orders of magnitude. However, computing better surrogates requires more computation per observation, which creates a fundamental trade-off between surrogate quality and subsample size that should be carefully considered in practice.</p>
</section>
<section id="model-comparison-for-large-data" class="level3" data-number="7.8.2">
<h3 data-number="7.8.2" class="anchored" data-anchor-id="model-comparison-for-large-data"><span class="header-section-number">7.8.2</span> Model comparison for large data</h3>
<p>When comparing models <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we are interested in the difference in predictive performance</p>
<p><span class="math display">\[
\operatorname{elpd}_D = \operatorname{elpd}_A - \operatorname{elpd}_B,
\]</span></p>
<p>along with its variance</p>
<p><span class="math display">\[
V(\operatorname{elpd}_D) = V(\operatorname{elpd}_A) + V(\operatorname{elpd}_B) - 2\operatorname{Cov}(\operatorname{elpd}_A, \operatorname{elpd}_B).
\]</span></p>
<p>The covariance term is crucial and often overlooked in practice. When models make similar predictions for most observations, which is common when comparing related models, the predictions are highly correlated, making <span class="math inline">\(\operatorname{Cov}(\operatorname{elpd}_A, \operatorname{elpd}_B)\)</span> large and positive. This correlation dramatically reduces the variance of the difference compared to naively summing individual variances.</p>
<p>This is why using a common subsample across models is essential. Different random subsamples lose this correlation and fail to capture the variance reduction, whereas the same subsample preserves the correlation structure and accurately estimates both <span class="math inline">\(\operatorname{elpd}_D\)</span> and its much smaller variance, for an exmple see <span class="quarto-unresolved-ref">?sec-sec-model-comparison-large-data</span>.</p>
</section>
<section id="previous-approaches-and-practical-limitations" class="level3" data-number="7.8.3">
<h3 data-number="7.8.3" class="anchored" data-anchor-id="previous-approaches-and-practical-limitations"><span class="header-section-number">7.8.3</span> Previous approaches and practical limitations</h3>
<p>Before describing the central difference estimator used in LOO-CV for large data, it is important to understand the limitations of previous methods for scaling LOO to large data and model comparison. One previous approach is the <strong>Hansen-Hurwitz (HH) estimator</strong> <span class="citation" data-cites="hansen_hurwitz_1943">(<a href="References.html#ref-hansen_hurwitz_1943" role="doc-biblioref">Hansen and Hurwitz 1943</a>)</span> which uses importance sampling with auxiliary information incorporated at the sampling stage. For estimating <span class="math inline">\(\operatorname{elpd}_{\text{loo}}\)</span>, observations are subsampled with probability proportional to an approximate LOO contribution <span class="math inline">\(\tilde{\pi}_i\)</span> giving</p>
<p><span class="math display">\[
\widehat{\operatorname{elpd}}_{\text{HH}} = \frac{1}{m} \sum_{j \in \mathcal{S}} \frac{1}{\tilde{\pi}_j} \pi_j,
\]</span></p>
<p>where <span class="math inline">\(\mathcal{S}\)</span> is the subsample of size <span class="math inline">\(m\)</span>. While the HH estimator works well for individual model evaluation, it has two key limitations for model comparison:</p>
<ol type="1">
<li><p>Since the auxiliary information <span class="math inline">\(\tilde{\pi}_i\)</span> is model-specific and used in the sampling step, each model requires a different subsample. Comparing models or estimating <span class="math inline">\(V(\operatorname{elpd}_D)\)</span> requires drawing additional subsamples for each quantity of interest, multiplying computational costs.</p></li>
<li><p>Using point estimates like <span class="math inline">\(\log p(y_i \mid \hat{\theta})\)</span> as auxiliary information ignores the effective number of parameters <span class="math inline">\(p_{\text{eff}}\)</span> and can lead to poor approximations for complex models and requiring larger subsample sizes.</p></li>
</ol>
<p>These practical limitations motivate the difference estimator approach described below, which uses the same subsample for all models and incorporates model complexity directly in the surrogate approximation.</p>
</section>
<section id="difference-estimator-for-large-data" class="level3" data-number="7.8.4">
<h3 data-number="7.8.4" class="anchored" data-anchor-id="difference-estimator-for-large-data"><span class="header-section-number">7.8.4</span> Difference estimator for large data</h3>
<p>The key to subsampling LOO for large datasets is the difference estimator, which corrects the bias in fast approximations of the full-data LOO. Let <span class="math inline">\(\pi_i = \log p(y_i\mid y_{-i})\)</span> denote the exact LOO predictive density for observation <span class="math inline">\(i\)</span>, and let <span class="math inline">\(\tilde\pi_i\)</span> be a computationally efficient approximation. For a simple random subsample <span class="math inline">\(\mathcal S\)</span> of size <span class="math inline">\(m\)</span>, the difference estimator is given by</p>
<p><span class="math display">\[
\widehat{\operatorname{elpd}}_{\text{diff, loo}}
= \sum_{i=1}^n \tilde\pi_i
+ \frac{n}{m} \sum_{j\in\mathcal S} (\pi_j - \tilde\pi_j).
\]</span></p>
<p>Its subsampling variance is</p>
<p><span class="math display">\[
V\bigl(\widehat{\operatorname{elpd}}_{\text{diff, loo}}\bigr)
= n^2\!\left(1-\frac{m}{n}\right) \frac{s_e^2}{m},
\]</span></p>
<p>where <span class="math inline">\(s_e^2 = \frac{1}{m-1} \sum_{j\in\mathcal S} (e_j-\bar e)^2\)</span> is the sample variance of the approximation error <span class="math inline">\(e_j=\pi_j-\tilde\pi_j\)</span>, and <span class="math inline">\(\bar e = \frac{1}{m} \sum_{j\in\mathcal S} e_j\)</span>.</p>
<p>The difference estimator has two key properties that make it ideal for large-data model comparison:</p>
<ol type="1">
<li><p>The variance decreases as the surrogate quality improves, e.g., as <span class="math inline">\(\tilde\pi_i \to \pi_i\)</span>, the approximation error <span class="math inline">\(e_j \to 0\)</span> and the subsampling variance vanishes.</p></li>
<li><p>The term <span class="math inline">\((1-m/n)\)</span> is a <strong>finite population correction factor</strong> that ensures the variance also vanishes as the subsample size approaches the full dataset size. This means we can start with a small subsample and incrementally increase it until we achieve the desired precision, without wasting computational effort.</p></li>
</ol>
<p>Crucially, the same subsample can be reused across all models. To estimate model differences <span class="math inline">\(\operatorname{elpd}_D = \operatorname{elpd}_A - \operatorname{elpd}_B\)</span>, we simply apply the difference estimator with difference surrogates <span class="math inline">\(\tilde\pi_{i,D} = \tilde\pi_{i,A} - \tilde\pi_{i,B}\)</span> and exact differences <span class="math inline">\(\pi_{j,D} = \pi_{j,A} - \pi_{j,B}\)</span> on the common subsample.</p>
<p>For model comparison, we also need the variability of pointwise ELPD contributions, <span class="math inline">\(\sigma^2_{\text{loo}} = \tfrac{1}{n}\sum_i (\pi_i-\bar\pi)^2\)</span>. Using the same subsample with squared surrogates <span class="math inline">\(\tilde\pi_i^2\)</span> yields the unbiased estimator</p>
<p><span class="math display">\[
\begin{align}
\hat{\sigma}^2_{\text{diff, loo}}
= \sum_{i=1}^n \tilde\pi_i^2 &amp;+ \frac{n}{m} \sum_{j\in\mathcal S} (\pi_j^2 - \tilde\pi_j^2) \\
&amp;\quad + \frac{1}{n}\biggl[\Bigl( \frac{n}{m}\sum_{j\in\mathcal S} (\pi_j-\tilde\pi_j) \Bigr)^2 - V\bigl(\widehat{\operatorname{elpd}}_{\text{diff, loo}}\bigr)\biggr] \\
&amp;\quad + \frac{1}{n}\biggl[ 2\Bigl(\sum_{i=1}^n \tilde\pi_i\Bigr)\widehat{\operatorname{elpd}}_{\text{diff, loo}} - \Bigl(\sum_{i=1}^n \tilde\pi_i\Bigr)^2 \biggr].
\end{align}
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Unbiasedness of the difference estimator
</div>
</div>
<div class="callout-body-container callout-body">
<p>The estimators <span class="math inline">\(\widehat{\operatorname{elpd}}_{\text{diff, loo}}\)</span> and <span class="math inline">\(\hat{\sigma}^2_{\text{diff, loo}}\)</span> are unbiased for <span class="math inline">\(\operatorname{elpd}_{\text{loo}}\)</span> and <span class="math inline">\(\sigma^2_{\text{loo}}\)</span>, respectively <span class="citation" data-cites="magnusson_2020">(<a href="References.html#ref-magnusson_2020" role="doc-biblioref">Magnusson et al. 2020</a>)</span>. In practice, <span class="math inline">\(\hat{\sigma}^2_{\text{diff, loo}}\)</span> tends to be optimistic since no general unbiased estimator of the true variability exists in cross-validation <span class="citation" data-cites="bengio_2004">(<a href="References.html#ref-bengio_2004" role="doc-biblioref">Bengio and Grandvalet 2004</a>)</span>.</p>
</div>
</div>
</section>
<section id="fast-loo-surrogates" class="level3" data-number="7.8.5">
<h3 data-number="7.8.5" class="anchored" data-anchor-id="fast-loo-surrogates"><span class="header-section-number">7.8.5</span> Fast LOO surrogates</h3>
<p>For the difference estimator to be efficient, we need good approximations of the LOO contributions. We want surrogates <span class="math inline">\(\tilde\pi_i\)</span> that</p>
<ol type="1">
<li>Approximate <span class="math inline">\(\pi_i\)</span> well in finite samples</li>
<li>Are computationally cheap</li>
<li>Converge in mean, <span class="math inline">\(\mathbb{E}|\pi_i - \tilde\pi_i| \to 0\)</span> as <span class="math inline">\(n \to \infty\)</span></li>
</ol>
<p>Notably, the third property ensures favorable scaling characteristics as the data size grows.</p>
<section id="practical-surrogates-plpd-and-lpd" class="level4" data-number="7.8.5.1">
<h4 data-number="7.8.5.1" class="anchored" data-anchor-id="practical-surrogates-plpd-and-lpd"><span class="header-section-number">7.8.5.1</span> Practical surrogates: PLPD and LPD</h4>
<p>In practice, the function <code>loo_subsample</code> in ArviZ implements two main surrogates.</p>
<p>The first is the <strong>point log predictive density (PLPD)</strong> and is given by</p>
<p><span class="math display">\[
\tilde\pi_i^{\text{PLPD}} = \log p(y_i \mid \hat\theta),
\]</span></p>
<p>where <span class="math inline">\(\hat\theta\)</span> is typically the posterior mean. This is computationally cheapest but ignores posterior uncertainty.</p>
<p>The second is the <strong>log predictive density (LPD)</strong> and is given by</p>
<p><span class="math display">\[
\tilde\pi_i^{\text{LPD}} = \log \left(\frac{1}{S} \sum_{s=1}^S p(y_i \mid \theta_s)\right),
\]</span></p>
<p>which averages over posterior draws before taking the logarithm. The approximation error <span class="math inline">\(e_j = \pi_j - \tilde\pi_j\)</span> directly affects the subsampling variance, so better surrogates allow smaller subsamples for the same precision.</p>
</section>
</section>
<section id="asymptotic-guarantees-and-assumptions" class="level3" data-number="7.8.6">
<h3 data-number="7.8.6" class="anchored" data-anchor-id="asymptotic-guarantees-and-assumptions"><span class="header-section-number">7.8.6</span> Asymptotic guarantees and assumptions</h3>
<p>The difference estimator has strong theoretical foundations, with convergence guarantees under mild regularity conditions. Remarkably, convergence accelerates as the data size grows, even when the subsample size and number of posterior draws are fixed, making the method more efficient precisely when it is needed most.</p>
<p>The required assumptions are standard regularity conditions satisfied by most common parametric models including regression, GLMs, and hierarchical models. For detailed theoretical treatment of the asymptotic properties and regularity conditions, see <span class="citation" data-cites="magnusson_2020">Magnusson et al. (<a href="References.html#ref-magnusson_2020" role="doc-biblioref">2020</a>)</span>.</p>
</section>
</section>
<section id="absolute-metrics" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="absolute-metrics"><span class="header-section-number">7.9</span> Absolute metrics</h2>
<p>In the previous sections, we have seen how to compare models using relative metrics. By relative we mean that we are comparing the models with respect to each other. For example, we can say that model A is better than model B because it has a higher ELPD value. But we can not, in general, judge a single model by its ELPD alone. In contrast, sometimes we are interested in absolute metrics. Some common absolute metrics are the root mean square error (RMSE), the mean absolute error (MAE), the coeﬀicient of determination (<span class="math inline">\(R^2\)</span>), etc. Interestingly, we can use PSIS-LOO-CV procedure to compute the leave-one-out cross-validation version of these metrics.</p>
<section id="loo-expectations-and-metrics" class="level3" data-number="7.9.1">
<h3 data-number="7.9.1" class="anchored" data-anchor-id="loo-expectations-and-metrics"><span class="header-section-number">7.9.1</span> LOO expectations and metrics</h3>
<p>From the PSIS procedure, we obtain a set of weights. The <code>loo</code> function utilizes these weights to estimate the ELPD we should have obtained if we have performed leave-one-out cross-validation. Furthermore, these weights can be used to estimate other quantities, such as the mean, standard deviation, and quantiles, as if we had performed leave-one-out cross-validation. For example, to compute the 25th and 75th percentiles we use:</p>
<div id="763f3220" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a>azp.loo_expectations(dt_rugby, kind<span class="op">=</span><span class="st">"quantile"</span>, probs<span class="op">=</span>[<span class="fl">0.25</span>, <span class="fl">0.75</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/arviz_stats/loo/helper_loo.py:1143: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>(&lt;xarray.DataArray 'home_points' (quantile: 2, match: 60)&gt; Size: 960B
 array([[44.        , 12.        , 25.        , 18.        , 14.        ,
         32.        , 21.        , 15.        , 16.        , 38.        ,
         16.        , 20.        , 10.        , 23.        , 10.        ,
         18.        ,  9.        , 21.        , 45.        , 20.        ,
         13.        , 33.        , 15.        , 17.        , 14.        ,
         30.        , 14.        , 11.        , 10.        , 22.        ,
         33.        , 13.        , 18.        , 11.        , 26.        ,
         10.        , 22.        , 15.        , 16.        , 37.        ,
         21.        , 14.        , 37.        , 24.        , 13.        ,
         10.        , 24.        , 12.        ,  8.        , 18.        ,
         20.        , 13.        , 20.        , 47.        , 14.        ,
         12.        , 25.        , 31.        , 14.        , 17.        ],
        [54.        , 18.        , 32.        , 24.        , 20.        ,
         41.        , 28.        , 21.        , 23.        , 47.        ,
         22.        , 28.        , 15.        , 31.        , 15.        ,
         25.        , 13.        , 28.        , 56.        , 27.        ,
         19.        , 42.        , 21.        , 23.        , 20.        ,
         39.        , 19.        , 16.        , 16.        , 28.        ,
         41.        , 19.        , 25.        , 16.        , 35.        ,
         16.        , 29.        , 21.        , 22.        , 46.        ,
         28.        , 20.        , 47.        , 31.        , 19.        ,
         14.        , 31.        , 17.        , 13.        , 25.        ,
         27.        , 18.98637825, 27.        , 57.        , 20.        ,
         17.        , 33.11938331, 39.        , 20.        , 23.        ]])
 Coordinates:
   * quantile   (quantile) float64 16B 0.25 0.75
   * match      (match) &lt;U16 4kB 'Wales Italy' ... 'Ireland England'
     home_team  (match) &lt;U8 2kB 'Wales' 'France' 'Ireland' ... 'France' 'Ireland'
     away_team  (match) &lt;U8 2kB 'Italy' 'England' ... 'Wales' 'England',
 &lt;xarray.DataArray 'home_points' (match: 60)&gt; Size: 480B
 array([0.81019699, 0.28836737, 0.19853754, 0.13917616, 0.3967199 ,
        0.23962001, 0.16479781, 0.14713066, 0.3616447 , 0.1013727 ,
        0.09210699, 0.17722584, 0.09801876, 0.73061293, 0.17059836,
        0.23174109, 0.25935113, 0.22608703, 0.11200082, 0.19183078,
        0.347671  , 0.62174049, 0.00583348, 0.04696175, 0.30153295,
        0.28010278, 0.3377815 , 0.09288675, 0.15444295, 0.74229683,
        0.35880752, 0.19010797, 0.21098666, 0.22112489, 0.17530626,
        0.12022844, 0.10181887, 0.14713066, 0.10800236, 0.23071062,
        0.25231008, 0.30349302, 0.4710015 , 0.17825569, 0.18154059,
        0.3013977 , 0.16174767, 0.23836638, 0.16261163, 0.23174109,
        0.14606708, 0.50457581, 0.17899662, 0.20756025, 0.28074787,
        0.14313128, 0.70480686, 0.41149501, 0.00931864, 0.08937109])
 Coordinates:
   * match      (match) &lt;U16 4kB 'Wales Italy' ... 'Ireland England'
     home_team  (match) &lt;U8 2kB 'Wales' 'France' 'Ireland' ... 'France' 'Ireland'
     away_team  (match) &lt;U8 2kB 'Italy' 'England' ... 'Wales' 'England')</code></pre>
</div>
</div>
<p>Similarly we may be interested in computing estimates of leave-one-out predictive metrics given a set of predictions and observations. For instance to compute the root mean square error we can do:</p>
<div id="7bd6891a" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a>azp.loo_metrics(dt_rugby, kind<span class="op">=</span><span class="st">"rmse"</span>, var_name<span class="op">=</span><span class="st">"home_points"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/arviz_stats/loo/helper_loo.py:1143: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>rmse(mean=11.0, se=1.2)</code></pre>
</div>
</div>
<p>Anoth</p>
<div id="122e01d1" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>azp.loo_r2(dt_rugby, var_name<span class="op">=</span><span class="st">"home_points"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/arviz_stats/loo/helper_loo.py:1143: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.70 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>loo_R2(mean=0.35, eti_lb=0.14, eti_ub=0.51)</code></pre>
</div>
</div>
<p>Notice that for <code>loo_metrics</code> and <code>loo_r2</code> if we have more than one variable we must specify the variable that we care using the <code>var_names</code> argument, like in the previous examples.</p>
</section>
<section id="loo-pit" class="level3" data-number="7.9.2">
<h3 data-number="7.9.2" class="anchored" data-anchor-id="loo-pit"><span class="header-section-number">7.9.2</span> LOO-PIT</h3>
<p>Another quantity of interest that we can obtain via PSIS-LOO-CV is the PIT values. As already mentioned in <a href="Prior_posterior_predictive_checks.html#sec-avoid-double-dipping" class="quarto-xref"><span>Section 5.2.4</span></a>, we often are interested in computing:</p>
<p><span class="math display">\[
p(\tilde y_i \le y_i \mid y_{-i})
\]</span></p>
<p>That is, we are evaluating the model’s ability to predict an observation when we remove that observation from the observed data. We can use PSIS-LOO_CV to estimate this from a single model fit.</p>
<div id="cell-fig-loo_pit" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a>azp.plot_loo_pit(dt_rugby, var_names<span class="op">=</span><span class="st">"home_points"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div id="fig-loo_pit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-loo_pit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="Model_comparison_files/figure-html/fig-loo_pit-output-1.png" width="458" height="209" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-loo_pit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2: LOO-PIT plot for the rugby model
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="other-information-criteria" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="other-information-criteria"><span class="header-section-number">7.10</span> Other information criteria</h2>
<p>PSIS-LOO-CV and WAIC converge asymptotically and are based on the same set of assumptions, so theoretically they are equivalent. However, in practice PSIS-LOO-CV is more robust and also offers a diagnostic that indicates when it could be failing (thanks to the Pareto adjustment). For this reason, ArviZ only implements PSIS-LOO-CV. We now briefly discuss two other information criteria that are somewhat popular.</p>
<p>Deviance Information Criteria, DIC, if we use the <em>bayes-o-meter™</em>, DIC is more Bayesian than AIC but less than WAIC. Although still popular, PSIS-LOO_CV (and also WAIC) have proven to be more useful both theoretically and empirically than DIC. Therefore we DO NOT recommend its use.</p>
<p>Bayesian Information Criterion (BIC) was proposed as a way to correct some of the problems with AIC, and the author provided a Bayesian rationale for it. But BIC is not really Bayesian in the sense that, like AIC, it assumes <em>flat</em> priors and uses maximum likelihood estimation. More importantly, BIC differs from AIC and WAIC in its objective. AIC and WAIC aim to reflect which model generalizes better to new data (predictive accuracy), while BIC tries to identify the <em>correct</em> model and is therefore more closely related to Bayes factors than to WAIC. In the next section, we discuss Bayes factors and how they differ from PSIS-LOO-CV and WAIC.</p>
</section>
<section id="bayes-factors" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="bayes-factors"><span class="header-section-number">7.11</span> Bayes factors</h2>
<p>An alternative to cross-validation, approximate cross-validation with LOO and information criteria is Bayes factors. It is common for Bayes factors to show up in the literature as a Bayesian alternative to frequentist hypothesis testing.</p>
<p>We can compare <span class="math inline">\(K\)</span> models by computing their <strong>marginal likelihood</strong>, <span class="math inline">\(p(y \mid M_k)\)</span>, i.e., the probability of the observed data <span class="math inline">\(Y\)</span> given the model <span class="math inline">\(M_K\)</span>. The marginal likelihood is the normalization constant of Bayes’ theorem. We can see this if we write Bayes’ theorem and make explicit the fact that all inferences depend on the model.</p>
<p><span class="math display">\[
p (\theta \mid Y, M_k ) = \frac{p(Y \mid \theta, M_k) p(\theta \mid M_k)}{p(Y \mid M_k)}
\]</span></p>
<p>where, <span class="math inline">\(Y\)</span> is the data, <span class="math inline">\(\theta\)</span> is the parameters, and <span class="math inline">\(M_K\)</span> is a model out of <span class="math inline">\(K\)</span> competing models.</p>
<p>If our main objective is to choose only one model, the <em>best</em> from a set of models, we can choose the one with the largest value of <span class="math inline">\(p(y \mid M_k)\)</span>. This is fine if we assume that all models have the same prior probability. Otherwise, we must calculate:</p>
<p><span class="math display">\[
p(M_k \mid y) \propto p(y \mid M_k) p(M_k)
\]</span></p>
<p>If, instead, our main objective is to compare models to determine which are more likely and to what extent, this can be achieved using the Bayes factors:</p>
<p><span class="math display">\[
BF_{01} = \frac{p(y \mid M_0)}{p(y \mid M_1)}
\]</span></p>
<p>That is the ratio between the marginal likelihood of two models. The higher the value of <span class="math inline">\(BF_{01}\)</span>, the <em>better</em> the model in the numerator (<span class="math inline">\(M_0\)</span> in this example). To facilitate the interpretation of the Bayes factors, and to put numbers into words, Harold Jeffreys proposed a scale for their interpretation, with levels of <em>support</em> or <em>strength</em>, see the following table.</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th><strong>Bayes Factor</strong></th>
<th><strong>Support</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1–3</td>
<td>Anecdotal</td>
</tr>
<tr class="even">
<td>3–10</td>
<td>Moderate</td>
</tr>
<tr class="odd">
<td>10–30</td>
<td>Strong</td>
</tr>
<tr class="even">
<td>30–100</td>
<td>Very Strong</td>
</tr>
<tr class="odd">
<td>&gt;100</td>
<td>Extreme</td>
</tr>
</tbody>
</table>
<p>Keep in mind that if you get numbers below 1, then the support is for <span class="math inline">\(M_1\)</span>, i.e., the model in the denominator. Tables are also available for those cases, but notice that you can simply take the inverse of the obtained value.</p>
<p>It is very important to remember that these rules are just conventions – simple guides at best. Results should always be put in the context of our problems and should be accompanied by enough detail so that others can assess for themselves whether they agree with our conclusions. The proof necessary to ensure something in particle physics, or in court, or to decide to carry out an evacuation in the face of a looming natural catastrophe is not the same.</p>
<section id="some-observations" class="level3" data-number="7.11.1">
<h3 data-number="7.11.1" class="anchored" data-anchor-id="some-observations"><span class="header-section-number">7.11.1</span> Some observations</h3>
<p>We will now briefly discuss some key facts about the marginal likelihood:</p>
<ul>
<li>The good: Occam’s razor included. Models with lots of parameters have a higher penalty than models with few parameters. The intuitive reason is that the greater the number of parameters, the more the prior <em>extends</em> with respect to the likelihood. An example where it is easy to see this is with nested models: for example, a polynomial of order 2 “contains” the models polynomial of order 1 and polynomial of order 0.</li>
<li>The bad: For many problems, the marginal likelihood cannot be calculated analytically. Also, approximating it numerically is usually a difficult task that in the best of cases requires specialized methods and, in the worst case, the estimates are either impractical or unreliable. In fact, the popularity of the MCMC methods is that they allow obtaining the posterior distribution without the need to calculate the marginal likelihood.</li>
<li>The ugly: The marginal likelihood depends <em>very sensitively</em> on the prior distribution of the parameters in each model <span class="math inline">\(p(\theta_k \mid M_k)\)</span>.</li>
</ul>
<p>It is important to note that the <em>good</em> and the <em>ugly</em> points are related. Using marginal likelihood to compare models is a good idea because it already includes a penalty for complex models (which helps us prevent overfitting), and at the same time, a change in the prior will affect the marginal likelihood calculations. At first, this sounds a bit silly; we already know that priors affect calculations (otherwise we could just avoid them). But we are talking about changes in the prior that would have a small effect in the posterior but a great impact on the value of the marginal likelihood.</p>
<p>The use of Bayes factors is often a watershed among Bayesians. The difficulty of its calculation and the sensitivity to the priors are some of the arguments against it. Another reason is that, like p-values and hypothesis testing in general, Bayes factors favor dichotomous thinking over the estimation of the “effect size.” In other words, instead of asking ourselves questions like: How many more years of life can a cancer treatment provide? We end up asking if the difference between treating and not treating a patient is “statistically significant.” Note that this last question can be useful in some contexts. The point is that in many other contexts, this type of question is not the question that interests us; we’re only interested in the one that we were taught to answer.</p>
</section>
<section id="calculation-of-bayes-factors" class="level3" data-number="7.11.2">
<h3 data-number="7.11.2" class="anchored" data-anchor-id="calculation-of-bayes-factors"><span class="header-section-number">7.11.2</span> Calculation of Bayes factors</h3>
<p>The marginal likelihood (and the Bayes factors derived from it) is generally not available in closed form, except for a few models. For this reason, many numerical methods have been devised for its calculation. Some of these methods are so simple and <a href="https://radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever">naive</a> that they work very poorly in practice. We are going to discuss only one way to compute them, once that can be applied under some particular cases.</p>
</section>
<section id="savagedickey-ratio" class="level3" data-number="7.11.3">
<h3 data-number="7.11.3" class="anchored" data-anchor-id="savagedickey-ratio"><span class="header-section-number">7.11.3</span> Savage–Dickey ratio</h3>
<p>There are times when we want to compare a null hypothesis <span class="math inline">\(H_0\)</span> (or null model) against an alternative <span class="math inline">\(H_1\)</span> hypothesis. For example, to answer the question “Is this coin biased?”, we could compare the value <span class="math inline">\(\theta = 0.5\)</span> (representing no bias) with the output of a model in which we allow <span class="math inline">\(\theta\)</span> to vary. For this type of comparison, the null model is nested within the alternative, which means that the null is a particular value of the model we are building. In those cases, calculating the Bayes factor is very easy and does not require any special methods. We only need to compare the prior and posterior evaluated at the null value (for example, <span class="math inline">\(\theta = 0.5\)</span>) under the alternative model. We can see that this is true from the following expression:</p>
<p><span class="math display">\[
BF_{01} = \frac{p(y \mid H_0)}{p(y \mid H_1)} \frac{p(\theta=0.5 \mid y, H_1)}{p(\theta=0.5 \mid H_1)}
\]</span></p>
<p>This is true only when <span class="math inline">\(H_0\)</span> is a particular case of <span class="math inline">\(H_1\)</span>, see <a href="https://statproofbook.github.io/P/bf-sddr">The Book of Statistical Proofs</a> <span class="citation" data-cites="soch_2024">(<a href="References.html#ref-soch_2024" role="doc-biblioref">Soch et al. 2024</a>)</span>.</p>
<p>Let’s do it. We only need to sample the prior and posterior for a model. Let’s try the BetaBinomial model with a Uniform prior:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="ppl">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true" href="">PyMC</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false" href="">CmdStanPy</a></li></ul>
<div class="tab-content" data-group="ppl">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div id="1bcd2545" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>y <span class="op">=</span> np.repeat([<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">50</span>, <span class="dv">50</span>])  <span class="co"># 50 heads, 50 tails</span></span>
<span id="cb21-2"><a href="#cb21-2"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_uni:</span>
<span id="cb21-3"><a href="#cb21-3"></a>    a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb21-4"><a href="#cb21-4"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb21-5"><a href="#cb21-5"></a>    idata_uni <span class="op">=</span> pm.sample(<span class="dv">2000</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb21-6"><a href="#cb21-6"></a>    idata_uni.extend(pm.sample_prior_predictive(<span class="dv">8000</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a><span class="co">## coming soon</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<p>And now we call <code>azp.plot_bf</code></p>
<div id="0afdea03" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>azp.plot_bf(idata_uni, var_names<span class="op">=</span><span class="st">"a"</span>, ref_val<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Model_comparison_files/figure-html/cell-17-output-1.png" width="454" height="209" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>In the previous Figure we can see one KDE for the prior (black) and one for the posterior (gray). The two black dots show that we evaluated both distributions at the value 0.5. We can see that the Bayes factor in favor of the null hypothesis, <code>BF_01</code>, is <span class="math inline">\(\approx 8\)</span>, which we can interpret as <em>moderate evidence</em> in favor of the null hypothesis.</p>
<p>As we have already discussed, the Bayes factors measure which model, as a whole, is better at explaining the data. This includes the prior, even for models that the prior has a relatively low impact on the computation of the posterior. We can also see this prior effect by comparing a second model to the null model.</p>
<p>If, instead, our model were a BetaBinomial with a prior Beta(30, 30), the <code>BF_01</code> would be lower ( on the Jeffrey scale). This is because, according to this model, the value of <span class="math inline">\(\theta=0.5\)</span> is much more likely a priori than for a Uniform prior, and therefore the prior and posterior will be much more similar. That is, it is not very to see that the posterior is concentrated around 0.5 after collecting data. Don’t just believe me, let’s calculate it:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset" data-group="ppl">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true" href="">PyMC</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false" href="">CmdStanPy</a></li></ul>
<div class="tab-content" data-group="ppl">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div id="a8f15c4e" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model_conc:</span>
<span id="cb24-2"><a href="#cb24-2"></a>    a <span class="op">=</span> pm.Beta(<span class="st">"a"</span>, <span class="dv">30</span>, <span class="dv">30</span>)</span>
<span id="cb24-3"><a href="#cb24-3"></a>    yl <span class="op">=</span> pm.Bernoulli(<span class="st">"yl"</span>, a, observed<span class="op">=</span>y)</span>
<span id="cb24-4"><a href="#cb24-4"></a>    idata_conc <span class="op">=</span> pm.sample(<span class="dv">2000</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-5"><a href="#cb24-5"></a>    idata_conc.extend(pm.sample_prior_predictive(<span class="dv">8000</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="co">## coming soon</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</div>
</div>
<div id="9f8a9131" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>azp.plot_bf(idata_conc, var_names<span class="op">=</span>[<span class="st">"a"</span>], ref_val<span class="op">=</span><span class="fl">0.5</span>)<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Model_comparison_files/figure-html/cell-20-output-1.png" width="454" height="209" class="figure-img"></p>
</figure>
</div>
</div>
</div>
<p>We can see that the <code>BF_01</code> is <span class="math inline">\(\approx 1.6\)</span>, which we can interpret as <em>anecdotal evidence</em> in favor of the null hypothesis (see the Jeffreys’ scale, discussed earlier).</p>
</section>
<section id="bayes-factors-vs-the-alternatives" class="level3" data-number="7.11.4">
<h3 data-number="7.11.4" class="anchored" data-anchor-id="bayes-factors-vs-the-alternatives"><span class="header-section-number">7.11.4</span> Bayes factors vs the alternatives</h3>
<p>We could say that the Bayes factors measure which model, as a whole, is better at explaining the data. This includes the details of the prior, no matter how similar the model predictions are. In many scenarios, this is not what interests us when comparing models. For many real problems, priors are not intended to be an accurate description of the <em>True</em> prior distribution of parameters; instead, they are often chosen using partial information and with the goal of providing some regularization. In these cases, we prefer to evaluate models in terms of how similar their predictions are. For those cases, we can use LOO.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-akaike_1974" class="csl-entry" role="listitem">
Akaike, H. 1974. <span>“A New Look at the Statistical Model Identification.”</span> <em>IEEE Transactions on Automatic Control</em> 19 (6): 716–23. <a href="https://doi.org/10.1109/TAC.1974.1100705">https://doi.org/10.1109/TAC.1974.1100705</a>.
</div>
<div id="ref-bengio_2004" class="csl-entry" role="listitem">
Bengio, Yoshua, and Yves Grandvalet. 2004. <span>“No Unbiased Estimator of the Variance of k-Fold Cross-Validation.”</span> <em>Journal of Machine Learning Research</em> 5: 1089–1105. <a href="https://jmlr.csail.mit.edu/papers/v5/grandvalet04a.html">https://jmlr.csail.mit.edu/papers/v5/grandvalet04a.html</a>.
</div>
<div id="ref-hansen_hurwitz_1943" class="csl-entry" role="listitem">
Hansen, Morris H., and William N. Hurwitz. 1943. <span>“On the Theory of Sampling from Finite Populations.”</span> <em>The Annals of Mathematical Statistics</em> 14 (4): 333–62. <a href="https://doi.org/10.1214/aoms/1177731360">https://doi.org/10.1214/aoms/1177731360</a>.
</div>
<div id="ref-magnusson_2020" class="csl-entry" role="listitem">
Magnusson, Måns, Michael Riis Andersen, Johan Jonasson, and Aki Vehtari. 2020. <span>“Leave-One-Out Cross-Validation for Model Comparison in Large Data.”</span> In <em>Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics</em>. Vol. 108. Proceedings of Machine Learning Research. PMLR. <a href="https://arxiv.org/abs/2001.00980">https://arxiv.org/abs/2001.00980</a>.
</div>
<div id="ref-paananen_2020" class="csl-entry" role="listitem">
Paananen, Topi, Juho Piironen, Paul-Christian Bürkner, and Aki Vehtari. 2020. <span>“Implicitly Adaptive Importance Sampling.”</span> <a href="https://arxiv.org/abs/1906.08850">https://arxiv.org/abs/1906.08850</a>.
</div>
<div id="ref-soch_2024" class="csl-entry" role="listitem">
Soch, Joram, Thomas J Faulkenberry, Kenneth Petrykowski, and Carsten Allefeld. 2024. <span>“The Book of Statistical Proofs.”</span> <a href="https://doi.org/10.5281/ZENODO.4305949">https://doi.org/10.5281/ZENODO.4305949</a>.
</div>
<div id="ref-vehtari_2017" class="csl-entry" role="listitem">
Vehtari, Aki, Andrew Gelman, and Jonah Gabry. 2017. <span>“Practical Bayesian Model Evaluation Using Leave-One-Out Cross-Validation and WAIC.”</span> <em>Statistics and Computing</em> 27 (5): 1413–32. <a href="https://doi.org/10.1007/s11222-016-9696-4">https://doi.org/10.1007/s11222-016-9696-4</a>.
</div>
<div id="ref-watanabe_2013" class="csl-entry" role="listitem">
Watanabe, Sumio. 2013. <span>“A <span>Widely</span> <span>Applicable</span> <span>Bayesian</span> <span>Information</span> <span>Criterion</span>.”</span> <em>Journal of Machine Learning Research</em> 14 (March): 867–97. <a href="https://dl.acm.org/doi/10.5555/2567709.2502609">https://dl.acm.org/doi/10.5555/2567709.2502609</a>.
</div>
<div id="ref-yao_2018" class="csl-entry" role="listitem">
Yao, Yuling, Aki Vehtari, Daniel Simpson, and Andrew Gelman. 2018. <span>“<span class="nocase">Using Stacking to Average Bayesian Predictive Distributions (with Discussion)</span>.”</span> <em>Bayesian Analysis</em> 13 (3): 917–1007. <a href="https://doi.org/10.1214/17-BA1091">https://doi.org/10.1214/17-BA1091</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../Chapters/Sensitivity_checks.html" class="pagination-link" aria-label="Prior and likelihood sensitivity checks">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Prior and likelihood sensitivity checks</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../Chapters/Model_comparison_large_data.html" class="pagination-link" aria-label="Model Comparison for Large Data">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Model Comparison for Large Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>